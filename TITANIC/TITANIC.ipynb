{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "okut-YZtQXC8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:22: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:22: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5704\\1124896037.py:22: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  df['Is_Adult_Male'] = df['Name'].str.contains('Mr\\.').astype(int)\n",
      "[I 2025-12-29 20:52:49,015] A new study created in memory with name: no-name-04c60205-e7dd-415f-b052-136fc323cc93\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:52:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:52:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:52:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:52:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:52:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:52:56,708] Trial 0 finished with value: 0.8441051905840637 and parameters: {'n_estimators': 148, 'max_depth': 10, 'learning_rate': 0.02636694037251538, 'subsample': 0.6397938232280019, 'colsample_bytree': 0.9169215712566697, 'weight_rf': 0.8735594330766981, 'weight_xgb': 0.32211178478785973}. Best is trial 0 with value: 0.8441051905840637.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:52:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:52:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:53:05,058] Trial 1 finished with value: 0.8454742440657934 and parameters: {'n_estimators': 323, 'max_depth': 9, 'learning_rate': 0.010573798927870437, 'subsample': 0.7005300218672186, 'colsample_bytree': 0.9700804469951145, 'weight_rf': 0.3370744890376365, 'weight_xgb': 0.5373826281807854}. Best is trial 1 with value: 0.8454742440657934.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:53:13,477] Trial 2 finished with value: 0.845543189205161 and parameters: {'n_estimators': 377, 'max_depth': 10, 'learning_rate': 0.029310560443310783, 'subsample': 0.5676314815099704, 'colsample_bytree': 0.8172744780894132, 'weight_rf': 0.928926928532449, 'weight_xgb': 0.9234550617609478}. Best is trial 2 with value: 0.845543189205161.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:53:20,409] Trial 3 finished with value: 0.8469122426868907 and parameters: {'n_estimators': 365, 'max_depth': 3, 'learning_rate': 0.025104414443518637, 'subsample': 0.919777002072235, 'colsample_bytree': 0.5637559168614232, 'weight_rf': 0.8001533819132416, 'weight_xgb': 0.30132076670420077}. Best is trial 3 with value: 0.8469122426868907.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:53:26,981] Trial 4 finished with value: 0.8441347385009357 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.04966637655058654, 'subsample': 0.9554762082443307, 'colsample_bytree': 0.5026137690655277, 'weight_rf': 0.8597443026011531, 'weight_xgb': 0.9244483017498368}. Best is trial 3 with value: 0.8469122426868907.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:53:32,920] Trial 5 finished with value: 0.8454742440657934 and parameters: {'n_estimators': 53, 'max_depth': 5, 'learning_rate': 0.010675565988281146, 'subsample': 0.5178328974579015, 'colsample_bytree': 0.8411594547844435, 'weight_rf': 0.5207808918866554, 'weight_xgb': 0.2212063000968889}. Best is trial 3 with value: 0.8469122426868907.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:53:40,673] Trial 6 finished with value: 0.8427065891854625 and parameters: {'n_estimators': 316, 'max_depth': 6, 'learning_rate': 0.01344355544073262, 'subsample': 0.9928361969726596, 'colsample_bytree': 0.5006375028708219, 'weight_rf': 0.6375672509199026, 'weight_xgb': 0.8861751660026675}. Best is trial 3 with value: 0.8469122426868907.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:53:47,731] Trial 7 finished with value: 0.8497586920122131 and parameters: {'n_estimators': 203, 'max_depth': 7, 'learning_rate': 0.09727065255000239, 'subsample': 0.6895182839743699, 'colsample_bytree': 0.616249425424106, 'weight_rf': 0.5730605002912206, 'weight_xgb': 0.5637150162729921}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:53:56,042] Trial 8 finished with value: 0.8371023342854329 and parameters: {'n_estimators': 477, 'max_depth': 6, 'learning_rate': 0.05120243312947255, 'subsample': 0.6603600586605789, 'colsample_bytree': 0.7582900484648389, 'weight_rf': 0.32785652412562694, 'weight_xgb': 0.6413083893544882}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:53:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:54:03,625] Trial 9 finished with value: 0.8384418398502905 and parameters: {'n_estimators': 245, 'max_depth': 4, 'learning_rate': 0.010464768772459228, 'subsample': 0.9850046182712403, 'colsample_bytree': 0.8404535599595471, 'weight_rf': 0.17141020984125876, 'weight_xgb': 0.700075139255607}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:54:09,856] Trial 10 finished with value: 0.8426967398798384 and parameters: {'n_estimators': 54, 'max_depth': 8, 'learning_rate': 0.0733734849880734, 'subsample': 0.8483368337541355, 'colsample_bytree': 0.64203247453153, 'weight_rf': 0.6094027895328097, 'weight_xgb': 0.47452774679084403}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:54:17,461] Trial 11 finished with value: 0.8455136412882892 and parameters: {'n_estimators': 423, 'max_depth': 3, 'learning_rate': 0.09861953423768752, 'subsample': 0.7968226473035787, 'colsample_bytree': 0.6241542044830566, 'weight_rf': 0.726216448561936, 'weight_xgb': 0.1221358951791732}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:54:26,271] Trial 12 finished with value: 0.8455037919826653 and parameters: {'n_estimators': 217, 'max_depth': 8, 'learning_rate': 0.021687920851751998, 'subsample': 0.8712798722414092, 'colsample_bytree': 0.6105245345411963, 'weight_rf': 0.4754492760527069, 'weight_xgb': 0.3928044691798792}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:54:33,491] Trial 13 finished with value: 0.8483108440854921 and parameters: {'n_estimators': 141, 'max_depth': 7, 'learning_rate': 0.019251272854617616, 'subsample': 0.7734500477249437, 'colsample_bytree': 0.6817909012116772, 'weight_rf': 0.7528849104366324, 'weight_xgb': 0.7317864335759634}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:54:41,521] Trial 14 finished with value: 0.8483206933911159 and parameters: {'n_estimators': 155, 'max_depth': 7, 'learning_rate': 0.016672472695817016, 'subsample': 0.7534111757171716, 'colsample_bytree': 0.7148206194534144, 'weight_rf': 0.7193837619584404, 'weight_xgb': 0.7664816434614148}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:54:48,487] Trial 15 finished with value: 0.8398896877770117 and parameters: {'n_estimators': 123, 'max_depth': 7, 'learning_rate': 0.04585236901453455, 'subsample': 0.7182143377061329, 'colsample_bytree': 0.7178135046557256, 'weight_rf': 0.46133940601451834, 'weight_xgb': 0.8096735618302953}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:54:56,545] Trial 16 finished with value: 0.8441051905840637 and parameters: {'n_estimators': 263, 'max_depth': 8, 'learning_rate': 0.016282580459095156, 'subsample': 0.611181462375677, 'colsample_bytree': 0.779212209200257, 'weight_rf': 0.9914883468503688, 'weight_xgb': 0.5806431068240556}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:54:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:55:03,925] Trial 17 finished with value: 0.8385009356840344 and parameters: {'n_estimators': 186, 'max_depth': 7, 'learning_rate': 0.03574476823686665, 'subsample': 0.7401836052421928, 'colsample_bytree': 0.685569188589488, 'weight_rf': 0.6663145836722724, 'weight_xgb': 0.7750216687368436}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:55:10,416] Trial 18 finished with value: 0.8441150398896877 and parameters: {'n_estimators': 88, 'max_depth': 5, 'learning_rate': 0.09873269736236398, 'subsample': 0.7938904551309214, 'colsample_bytree': 0.572677049118379, 'weight_rf': 0.3758387049526605, 'weight_xgb': 0.503010146682718}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:55:17,889] Trial 19 finished with value: 0.8427065891854625 and parameters: {'n_estimators': 191, 'max_depth': 9, 'learning_rate': 0.03713764253564942, 'subsample': 0.6970232218799617, 'colsample_bytree': 0.7097548916189201, 'weight_rf': 0.5657149550164443, 'weight_xgb': 0.6373494476799193}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:55:25,849] Trial 20 finished with value: 0.8371220328966806 and parameters: {'n_estimators': 298, 'max_depth': 6, 'learning_rate': 0.06261409099541523, 'subsample': 0.8432399509151656, 'colsample_bytree': 0.5555812612609289, 'weight_rf': 0.17855393762161637, 'weight_xgb': 0.8622425907309282}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:55:32,677] Trial 21 finished with value: 0.8497291440953412 and parameters: {'n_estimators': 137, 'max_depth': 7, 'learning_rate': 0.018379336482589183, 'subsample': 0.7574077828097066, 'colsample_bytree': 0.6689633540382562, 'weight_rf': 0.7263018115808375, 'weight_xgb': 0.7353190824899333}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:55:39,271] Trial 22 finished with value: 0.8497192947897172 and parameters: {'n_estimators': 109, 'max_depth': 7, 'learning_rate': 0.016150419379961183, 'subsample': 0.6649949547513659, 'colsample_bytree': 0.6570559174078356, 'weight_rf': 0.6988648222092886, 'weight_xgb': 0.6900858424394647}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:55:45,884] Trial 23 finished with value: 0.8468826947700187 and parameters: {'n_estimators': 110, 'max_depth': 8, 'learning_rate': 0.013697064707042792, 'subsample': 0.5927031223135815, 'colsample_bytree': 0.6558050858773904, 'weight_rf': 0.8066208128154579, 'weight_xgb': 0.6216667967478996}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:55:52,202] Trial 24 finished with value: 0.8469122426868907 and parameters: {'n_estimators': 94, 'max_depth': 9, 'learning_rate': 0.02070978286098122, 'subsample': 0.664032535395714, 'colsample_bytree': 0.595084892721584, 'weight_rf': 0.6526334798308194, 'weight_xgb': 0.6854960560577145}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:55:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:55:59,279] Trial 25 finished with value: 0.8469122426868907 and parameters: {'n_estimators': 232, 'max_depth': 6, 'learning_rate': 0.014901917773926424, 'subsample': 0.5584830877819729, 'colsample_bytree': 0.6503912346632101, 'weight_rf': 0.5733887808672095, 'weight_xgb': 0.47414235094481255}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:56:06,662] Trial 26 finished with value: 0.8455136412882892 and parameters: {'n_estimators': 179, 'max_depth': 7, 'learning_rate': 0.023316893833557773, 'subsample': 0.6788697100064176, 'colsample_bytree': 0.5403150703875084, 'weight_rf': 0.4359552878309606, 'weight_xgb': 0.4170036569197404}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:56:13,209] Trial 27 finished with value: 0.8497094454840933 and parameters: {'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.018361525309509102, 'subsample': 0.7290805316912785, 'colsample_bytree': 0.785859394715246, 'weight_rf': 0.6939900862698272, 'weight_xgb': 0.8253651179181578}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:56:19,589] Trial 28 finished with value: 0.8455037919826653 and parameters: {'n_estimators': 123, 'max_depth': 5, 'learning_rate': 0.012698127528246044, 'subsample': 0.6190091741766601, 'colsample_bytree': 0.6804253714587323, 'weight_rf': 0.5219875423608848, 'weight_xgb': 0.9995565767274908}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:56:27,165] Trial 29 finished with value: 0.8426967398798386 and parameters: {'n_estimators': 147, 'max_depth': 9, 'learning_rate': 0.029647730563545985, 'subsample': 0.6377112501286951, 'colsample_bytree': 0.9012346960107669, 'weight_rf': 0.8602742234026869, 'weight_xgb': 0.6012156192913698}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:56:34,611] Trial 30 finished with value: 0.8385009356840343 and parameters: {'n_estimators': 219, 'max_depth': 10, 'learning_rate': 0.07253275947714165, 'subsample': 0.7971577742727779, 'colsample_bytree': 0.5930083825560628, 'weight_rf': 0.7592518091998611, 'weight_xgb': 0.6940428935897293}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:56:40,916] Trial 31 finished with value: 0.8469023933812666 and parameters: {'n_estimators': 77, 'max_depth': 8, 'learning_rate': 0.01849428529416902, 'subsample': 0.7246904139810534, 'colsample_bytree': 0.783746536473459, 'weight_rf': 0.6834691223524948, 'weight_xgb': 0.8272059584878204}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:56:48,621] Trial 32 finished with value: 0.8469122426868905 and parameters: {'n_estimators': 160, 'max_depth': 7, 'learning_rate': 0.02598919246794261, 'subsample': 0.6899594776198602, 'colsample_bytree': 0.7511912780785558, 'weight_rf': 0.6105371430565548, 'weight_xgb': 0.542396362682532}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:56:55,163] Trial 33 finished with value: 0.8426868905742145 and parameters: {'n_estimators': 102, 'max_depth': 8, 'learning_rate': 0.017419034779437313, 'subsample': 0.7540273573797664, 'colsample_bytree': 0.9785881138601249, 'weight_rf': 0.7926191718552081, 'weight_xgb': 0.7591687477368138}. Best is trial 7 with value: 0.8497586920122131.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:56:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:57:01,696] Trial 34 finished with value: 0.8511080468826947 and parameters: {'n_estimators': 81, 'max_depth': 9, 'learning_rate': 0.012001421532509125, 'subsample': 0.644995178490818, 'colsample_bytree': 0.8939772723281512, 'weight_rf': 0.9287494075741388, 'weight_xgb': 0.660981206519559}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:57:08,629] Trial 35 finished with value: 0.848300994779868 and parameters: {'n_estimators': 127, 'max_depth': 9, 'learning_rate': 0.012380740868703721, 'subsample': 0.6486062268419078, 'colsample_bytree': 0.9161268403090287, 'weight_rf': 0.949443943918156, 'weight_xgb': 0.5510707559661587}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:57:14,825] Trial 36 finished with value: 0.8426573426573427 and parameters: {'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.011073419013670979, 'subsample': 0.5697687381953871, 'colsample_bytree': 0.9448427387067707, 'weight_rf': 0.8960584323189791, 'weight_xgb': 0.6562201570902109}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:57:22,048] Trial 37 finished with value: 0.8426868905742145 and parameters: {'n_estimators': 168, 'max_depth': 10, 'learning_rate': 0.014989735266776537, 'subsample': 0.5174924979257787, 'colsample_bytree': 0.8779380750392769, 'weight_rf': 0.8210564909477036, 'weight_xgb': 0.41910449638311076}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:57:29,059] Trial 38 finished with value: 0.8398896877770117 and parameters: {'n_estimators': 274, 'max_depth': 4, 'learning_rate': 0.012436619819953346, 'subsample': 0.631703890273387, 'colsample_bytree': 0.6282071155113562, 'weight_rf': 0.9250740189778504, 'weight_xgb': 0.5814043437569676}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:57:36,875] Trial 39 finished with value: 0.8441248891953117 and parameters: {'n_estimators': 364, 'max_depth': 6, 'learning_rate': 0.03407502771078566, 'subsample': 0.5895794017933327, 'colsample_bytree': 0.8137614971061415, 'weight_rf': 0.8447153686863598, 'weight_xgb': 0.7275440133576662}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:57:44,367] Trial 40 finished with value: 0.8483206933911159 and parameters: {'n_estimators': 211, 'max_depth': 10, 'learning_rate': 0.011546842392372707, 'subsample': 0.703842901435449, 'colsample_bytree': 0.733999411733005, 'weight_rf': 0.9737649668864505, 'weight_xgb': 0.9695203656998739}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:57:50,678] Trial 41 finished with value: 0.8468925440756427 and parameters: {'n_estimators': 74, 'max_depth': 9, 'learning_rate': 0.014926354466622577, 'subsample': 0.6669547928638373, 'colsample_bytree': 0.8611918098194703, 'weight_rf': 0.6957571703376743, 'weight_xgb': 0.8932046598462684}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:57:57,311] Trial 42 finished with value: 0.8440953412784399 and parameters: {'n_estimators': 76, 'max_depth': 8, 'learning_rate': 0.0237812134931496, 'subsample': 0.728952865774634, 'colsample_bytree': 0.7989206890506292, 'weight_rf': 0.6193318897677361, 'weight_xgb': 0.8368329116003699}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:57:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:58:04,244] Trial 43 finished with value: 0.8469220919925146 and parameters: {'n_estimators': 108, 'max_depth': 7, 'learning_rate': 0.019459810425550117, 'subsample': 0.8276734255806615, 'colsample_bytree': 0.6619350209611171, 'weight_rf': 0.7474282106545015, 'weight_xgb': 0.6607090740550505}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:58:11,634] Trial 44 finished with value: 0.8454840933714174 and parameters: {'n_estimators': 135, 'max_depth': 8, 'learning_rate': 0.021917753677125527, 'subsample': 0.7722594167382703, 'colsample_bytree': 0.8408409653607113, 'weight_rf': 0.5455318171426093, 'weight_xgb': 0.7937670559317865}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:58:17,786] Trial 45 finished with value: 0.8426967398798386 and parameters: {'n_estimators': 65, 'max_depth': 7, 'learning_rate': 0.02761290287958521, 'subsample': 0.8904817108393689, 'colsample_bytree': 0.5356222163267114, 'weight_rf': 0.901162822315059, 'weight_xgb': 0.7193110618896762}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:58:26,882] Trial 46 finished with value: 0.8427262877967102 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.04262884257141943, 'subsample': 0.683598423375662, 'colsample_bytree': 0.9598151102988949, 'weight_rf': 0.7780384242227822, 'weight_xgb': 0.9258614275296205}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:58:33,451] Trial 47 finished with value: 0.8454939426770413 and parameters: {'n_estimators': 98, 'max_depth': 8, 'learning_rate': 0.010260206724683562, 'subsample': 0.7065818058158297, 'colsample_bytree': 0.6928064765575813, 'weight_rf': 0.7052782913388687, 'weight_xgb': 0.2850248396643805}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:58:40,077] Trial 48 finished with value: 0.841288289175613 and parameters: {'n_estimators': 116, 'max_depth': 7, 'learning_rate': 0.08577355053603992, 'subsample': 0.7717947555421922, 'colsample_bytree': 0.611409111814156, 'weight_rf': 0.5811841301037168, 'weight_xgb': 0.743791064174991}. Best is trial 34 with value: 0.8511080468826947.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 20:58:47,104] Trial 49 finished with value: 0.8469122426868907 and parameters: {'n_estimators': 195, 'max_depth': 6, 'learning_rate': 0.016021950389595724, 'subsample': 0.739428074178436, 'colsample_bytree': 0.7302138012760052, 'weight_rf': 0.6506401435257543, 'weight_xgb': 0.6787081451404983}. Best is trial 34 with value: 0.8511080468826947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      " CV : 85.11%\n",
      "   : 86.59%\n",
      "best_params = {\n",
      "    'n_estimators': 81,\n",
      "    'max_depth': 9,\n",
      "    'learning_rate': 0.012001421532509125,\n",
      "    'subsample': 0.644995178490818,\n",
      "    'colsample_bytree': 0.8939772723281512,\n",
      "    'weight_rf': 0.9287494075741388,\n",
      "    'weight_xgb': 0.660981206519559,\n",
      "    'random_state': 42\n",
      "}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [20:58:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"weight_rf\", \"weight_xgb\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "#from sklearn.calibration import CalibratedClassifierCV\n",
    "path = r'C:\\Users\\user\\Documents\\GitHub\\Notebooks-on-ml\\TITANIC\\Data\\train.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "train_df_raw, val_df_raw = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "def get_safe_survival_mapping(train_fs, test_fs):\n",
    "    train_fs = train_fs.copy()\n",
    "    test_fs = test_fs.copy()\n",
    "\n",
    "    for df in [train_fs, test_fs]:\n",
    "        df['Surname'] = df['Name'].apply(lambda x: x.split(',')[0])\n",
    "        df['Is_Adult_Male'] = df['Name'].str.contains('Mr\\.').astype(int)\n",
    "        \n",
    "    train_fs['Family_Survival'] = 2\n",
    "    test_fs['Family_Survival'] = 2\n",
    "\n",
    "    for _, group in train_fs.groupby(['Surname', 'Fare']):\n",
    "        if len(group) > 1:\n",
    "            for ind, row in group.iterrows():\n",
    "                if row['Is_Adult_Male'] == 1:\n",
    "                    train_fs.loc[ind, 'Family_Survival'] = 0\n",
    "                else:\n",
    "                    others = group.drop(ind)\n",
    "                    if others['Survived'].max() == 1.0:\n",
    "                        train_fs.loc[ind, 'Family_Survival'] = 1\n",
    "                    elif others['Survived'].max() == 0.0:\n",
    "                        train_fs.loc[ind, 'Family_Survival'] = 0\n",
    "    for _, group in train_fs.groupby('Ticket'):\n",
    "        if len(group) > 1:\n",
    "            for ind, row in group.iterrows():\n",
    "                if train_fs.loc[ind, 'Family_Survival'] == 2:\n",
    "                    if row['Is_Adult_Male'] == 1:\n",
    "                        train_fs.loc[ind, 'Family_Survival'] = 0\n",
    "                    else: \n",
    "                        others = group.drop(ind)\n",
    "                        if others['Survived'].max() == 1.0:\n",
    "                            train_fs.loc[ind, 'Family_Survival'] = 1\n",
    "                        elif others['Survived'].max() == 0.0:\n",
    "                            train_fs.loc[ind, 'Family_Survival'] = 0\n",
    "\n",
    "    for ind, row in test_fs.iterrows():\n",
    "        if row['Is_Adult_Male'] == 1:\n",
    "            test_fs.loc[ind, 'Family_Survival'] = 0\n",
    "            continue\n",
    "        fam_in_train = train_fs[(train_fs['Surname'] == row['Surname']) & (train_fs['Fare'] == row['Fare'])]\n",
    "        ticket_in_train = train_fs[train_fs['Ticket'] == row['Ticket']]\n",
    "\n",
    "        combined = pd.concat([fam_in_train, ticket_in_train])\n",
    "\n",
    "        if len(combined) > 0:\n",
    "            if combined['Survived'].max() == 1.0:\n",
    "                test_fs.loc[ind, 'Family_Survival'] = 1\n",
    "            elif combined['Survived'].max() == 0.0:\n",
    "                test_fs.loc[ind, 'Family_Survival'] = 0\n",
    "\n",
    "    full_mapping = pd.concat([train_fs[['PassengerId', 'Family_Survival']],\n",
    "                                    test_fs[['PassengerId', 'Family_Survival']]])\n",
    "    return full_mapping\n",
    "\n",
    "def fill_missing_fare(df):\n",
    "    return df.groupby(['Pclass', 'Embarked'])['Fare_Individual'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "def prepare_data(df_input, survival_mapping, stats_df=None):\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['Ticket_Group_Size'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "    \n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(float)\n",
    "    df['IsMother'] = ((df['Sex'] == 1) & (df['Parch'] > 0) & (df['Age'] > 18)).astype(float)\n",
    "    df['IsChild'] = (df['Age'] < 14).astype(float)\n",
    "    df['Fare_Log'] = df['Fare'].apply(lambda x: np.log1p(x) if x > 0 else 0)\n",
    "    \n",
    "    df['Has_Cabin'] = df['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "    df['Deck'] = df['Cabin'].str[0].fillna('M')\n",
    "    deck_mapping = {'B': 0.74, 'D': 0.75, 'E': 0.75, 'C': 0.59, 'A': 0.50, 'T': 0.50, 'F': 0.61, 'G': 0.40, 'M': 0.23}\n",
    "    df['Deck_Score'] = df['Deck'].map(deck_mapping)\n",
    "    \n",
    "    source_df = stats_df if stats_df is not None else df\n",
    "    if 'Survived' in source_df.columns:\n",
    "        temp_source = source_df.copy()\n",
    "        temp_source['Deck'] = temp_source['Cabin'].str[0].fillna('M')\n",
    "        stats = temp_source.groupby(['Pclass', 'Deck'])['Survived'].mean().reset_index()\n",
    "        stats.columns = ['Pclass', 'Deck', 'Group_Survival_Rate']\n",
    "        df = df.merge(stats, on=['Pclass', 'Deck'], how='left')\n",
    "    \n",
    "    df['Group_Survival_Rate'] = df['Group_Survival_Rate'].fillna(df['Group_Survival_Rate'].median())\n",
    "    \n",
    "    df = df.merge(survival_mapping, on='PassengerId', how='left')\n",
    "    df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "    df['Title'] = df['Title'].replace(['Rev', 'Dr'], 'Service')\n",
    "    df['Title'] = df['Title'].replace(['Jonkheer', 'Don', 'Sir', 'Lady', 'Countess', 'Dona'], 'Noble')\n",
    "    df['Title'] = df['Title'].replace(['Capt', 'Col', 'Major'], 'Officer')\n",
    "    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    df['Age'] = df.groupby(['Pclass', 'Sex', 'Title'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    cols_to_drop = ['Name', 'Ticket', 'Cabin', 'PassengerId', 'SibSp', 'Parch', 'Pclass_Deck']\n",
    "    df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    return df.astype(float)\n",
    "\n",
    "fs_map = get_safe_survival_mapping(train_df_raw, val_df_raw)\n",
    "\n",
    "X_train = prepare_data(train_df_raw, fs_map).drop(columns=['Survived'])\n",
    "y_train = train_df_raw['Survived']\n",
    "\n",
    "X_val = prepare_data(val_df_raw, fs_map).drop(columns=['Survived'])\n",
    "y_val = val_df_raw['Survived']\n",
    "\n",
    "X_val = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "def objective(trial):\n",
    "    xgb_params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'random_state': 42,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    w1 = trial.suggest_float('weight_rf', 0.1, 1.0)\n",
    "    w2 = trial.suggest_float('weight_xgb', 0.1, 1.0)\n",
    "    \n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=370, max_depth=6, min_samples_split=12, \n",
    "        min_samples_leaf=4, random_state=42\n",
    "    )\n",
    "    \n",
    "    xgb_model = XGBClassifier(**xgb_params)\n",
    "    \n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[('rf', rf_model), ('xgb', xgb_model)],\n",
    "        voting='soft',\n",
    "        weights=[w1, w2]\n",
    "    )\n",
    "    \n",
    "    score = cross_val_score(ensemble, X_train, y_train, cv=5).mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "xgb_best_params = study.best_params.copy()\n",
    "w_rf = xgb_best_params.pop('weight_rf')\n",
    "w_xgb = xgb_best_params.pop('weight_xgb')\n",
    "best_xgb = XGBClassifier(**study.best_params, random_state=42)\n",
    "best_rf = RandomForestClassifier(n_estimators=370, max_depth=6, min_samples_split=12, min_samples_leaf=4, random_state=42)\n",
    "\n",
    "#calibrated_xgb = CalibratedClassifierCV(best_xgb, method='sigmoid', cv=5)\n",
    "#calibrated_rf = CalibratedClassifierCV(best_rf, method='sigmoid', cv=5)\n",
    "\n",
    "final_model = VotingClassifier(\n",
    "    estimators=[('rf', best_rf), ('xgb', best_xgb)],\n",
    "    voting='soft',\n",
    "    weights=[w_rf, w_xgb]\n",
    ")\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"-\" * 30)\n",
    "print(f\" CV : {study.best_value:.2%}\")\n",
    "print(f\"   : {final_model.score(X_val, y_val):.2%}\")\n",
    "print(\"best_params = {\")\n",
    "for key, value in study.best_params.items():\n",
    "    if isinstance(value, str):\n",
    "        print(f\"    '{key}': '{value}',\")\n",
    "    else:\n",
    "        print(f\"    '{key}': {value},\")\n",
    "print(\"    'random_state': 42\")\n",
    "print(\"}\") \n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deck_T                 0.000000\n",
      "Title_Noble            0.000000\n",
      "Deck_G                 0.000000\n",
      "Title_the Countess     0.000000\n",
      "Deck_F                 0.000252\n",
      "Title_Officer          0.000400\n",
      "Deck_A                 0.000471\n",
      "Deck_D                 0.000931\n",
      "Embarked_Q             0.002091\n",
      "Deck_C                 0.002401\n",
      "Deck_B                 0.003364\n",
      "Deck_E                 0.003880\n",
      "Title_Master           0.004542\n",
      "Title_Service          0.004863\n",
      "Embarked_C             0.005881\n",
      "IsAlone                0.005883\n",
      "Embarked_S             0.010595\n",
      "IsMother               0.011470\n",
      "IsChild                0.013427\n",
      "Deck_M                 0.018000\n",
      "Has_Cabin              0.022575\n",
      "Ticket_Group_Size      0.031814\n",
      "FamilySize             0.032279\n",
      "Deck_Score             0.034777\n",
      "Age                    0.041132\n",
      "Pclass                 0.041650\n",
      "Fare                   0.046705\n",
      "Title_Miss             0.047380\n",
      "Family_Survival        0.054003\n",
      "Fare_Log               0.056495\n",
      "Group_Survival_Rate    0.065788\n",
      "Title_Mrs              0.072114\n",
      "Sex                    0.181406\n",
      "Title_Mr               0.183434\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'Actual')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAGwCAYAAAD8AYzHAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAL7BJREFUeJzt3QtcVWW6x/FnbcUNgqB4AbyglBe0rAxNMdMyjMxjOtp1bLK0m5k30oo5ajZpGFNp3ifHsazsYqZpM+kxKh0nVLR0upKmhTdQJwHFuAj7fN63A8edaHsv92LD4vedz/rIXmu718vqePjzPO+7luFyuVwCAABggsPMXwIAACBIAACAC0JFAgAAmEaQAAAAphEkAACAaQQJAABgGkECAACYRpAAAACm1RUbCuryiL+HAFRLxzPm+XsIQLUTWLfm/Fz6+fPq92+YigQAADDNlhUJAACqFcO+v7cTJAAAsJph2PYaEyQAALCaYd+KhH2/MwAAYDkqEgAAWM2gtQEAAEwHCYdtr519vzMAAGA5WhsAAFjNoLUBAABMBwmHba+dfb8zAABgOVobAABYzaC1AQAATAcJh22vnX2/MwAAYDlaGwAAWM2gtQEAAEwHCYdtrx0VCQAArGbYtyJh34gEAAAsR0UCAACrGfb9vZ0gAQCA1Qz7Bgn7fmcAAMByBAkAACz/aWv4ZvPSiRMnZPz48dK6dWsJCgqSnj17SkZGRsVxl8slU6dOlaioKH08ISFBdu/e7d235vWoAACA960Nwwebl+677z7ZsGGDvPrqq/LFF1/IDTfcoMPCwYMH9fHU1FSZM2eOLFq0SLZu3SrBwcGSmJgohYWFHp+DIAEAgA39/PPPsnLlSh0WevfuLW3btpVp06bpPxcuXKirEbNnz5bJkyfLoEGD5LLLLpNly5bJoUOHZPXq1R6fhyABAEBV3EfCuPCtqKhI8vPz3Ta1rzKnT5+W0tJSCQwMdNuvWhibN2+Wffv2SXZ2tq5QlAsLC5Pu3btLenq6x98aQQIAgBrS2khJSdE/7M/c1L7KNGjQQOLj4+Xpp5/WVQYVKl577TUdEg4fPqxDhBIREeH299Tr8mOeIEgAAFBDJCcnS15entum9p2LmhuhWhgtWrQQp9Op50Pceeed4nD47sc/QQIAgBrS2nA6nRIaGuq2qX3ncvHFF8vGjRvl5MmTsn//ftm2bZuUlJTIRRddJJGRkfo9OTk5bn9HvS4/5gmCBAAANl21UU6txlBLPI8fPy7r16/XkytjYmJ0YEhLS6t4n5pzoVZvqJaIp7izJQAANn1o1/r163Vro0OHDrJnzx6ZNGmSxMbGyr333iuGYeh7TEyfPl3atWung8WUKVOkefPmMnjwYI/PQZAAAMCm8v5vDsWBAwckPDxchg4dKjNmzJCAgAB9/LHHHpOCggJ54IEHJDc3V3r16iXr1q07a6XH+RguFVVsJqjLI/4eAlAtHc+Y5+8hANVOYBX8Sh104ws++Zyf1yVJdUNFAgAAm7Y2qgKTLQEAgGlUJAAAsJph39/bCRIAAFjNoLUBAABwFioSAABYzaC1AQAACBJnsW9EAgAAlqO1AQCA1Qz7TrYkSAAAYDXDvg0AggQAAFYz7FuRsG9EAgAAlqMiAQCA1Qz7/t5OkAAAwGoGrQ0AAICzUJEAAMBiho0rEgQJAAAsZtg4SNh39gcAALAcFQkAAKxm2PcSEyQAALCYQWsDAADgbFQkAACwmGHjigRBAgAAixkECQAAQJA4G8s/AQCAabQ2AACwmmHfS0yQAADAYoaN50jQ2gAAAKZRkQAAwGKGjSsSBAkAACxm2DhI0NoAAACmESQAAKiCioThg80bpaWlMmXKFImJiZGgoCC5+OKL5emnnxaXy1XxHvX11KlTJSoqSr8nISFBdu/e7dV5CBIAAFjN8NHmhWeffVYWLlwo8+bNk2+++Ua/Tk1Nlblz51a8R72eM2eOLFq0SLZu3SrBwcGSmJgohYWFHp+HORIAANjQp59+KoMGDZIBAwbo123atJE33nhDtm3bVlGNmD17tkyePFm/T1m2bJlERETI6tWr5Y477vDoPFQkAACoIa2NoqIiyc/Pd9vUvsr07NlT0tLS5LvvvtOvd+3aJZs3b5b+/fvr1/v27ZPs7GzdzigXFhYm3bt3l/T0dI+/N4IEAAA1JEikpKToH/ZnbmpfZZ544gldVYiNjZWAgADp0qWLjB8/XoYNG6aPqxChqArEmdTr8mOeoLUBAEANWf6ZnJwsSUlJbvucTmel73377bfl9ddfl+XLl8sll1wiO3fu1EGiefPmMnz4cPEVggQAADWE0+k8Z3D4tUmTJlVUJZTOnTvLjz/+qCsYKkhERkbq/Tk5OXrVRjn1+oorrvB4TLQ2AACw4aqNU6dOicPh/mO+Tp06UlZWpr9Wy0JVmFDzKMqpORdq9UZ8fLzH56EiAQCADe9sOXDgQJkxY4ZER0fr1sbnn38uL7zwgowYMaJiTKrVMX36dGnXrp0OFuq+E6r1MXjwYI/PQ5AAAMCG5s6dq4PBww8/LEeOHNEB4cEHH9Q3oCr32GOPSUFBgTzwwAOSm5srvXr1knXr1klgYKDH5zFcZ97iyiaCujzi7yEA1dLxjHn+HgJQ7QRWwa/Ukfe/45PPyV58i1Q3VCQAALCYwUO7AAAAzkZFAgAAixk2rkgQJAAAsJph30vMfSQAAIBpVCQAALCYQWsDAAAQJM5GRQIAAIsZNq5IMEcCAACYRkUCAACrGfa9xAQJAAAsZtDaAAAAOBsVCVywkPpOefLh/5Kb+14uTRuFyK7MAzIx9R3Z8XVWxXs6xETI9HGD5Zor20rdug75dm+23Dnxr7I/+zj/BVBrFBSclPlzXpSP0j6Un376j8R27CSPPfFHubTzZf4eGixm2LgiQZDABVs49ffSqW1zGTH5FTl8NE/uvOkq+fuiMXLl0Oly6GiexLRsIml/S5JXVn8q0xf+XfILCqXTxVFSWFTC1UetMm3qZNmze7fMmJkqTZs2k7+/v0YevO9eeXfNPyQiIsLfw4OFDBsHCVZt4IIEOgNk8PVXyH/PXi3/+ux72bv/mMz4yz/k+/1H5f5br9HveeqRgbJ+81fy3y++p6sV+w4ck79v/EKOHj/J1UetUVhYKGkb/kcmPDpJ4rp2k+jWrWXU6DHSKrq1rHhzub+HB5hGkMAFqVvHIXXr1pHCYvfqgqo29OxysU7hN/a6RHZnHZE180fLj2kpsmnZRBl4LaVc1C6lpaeltLRUnE6n2371+vPPP/PbuFA1DMPwyVYd+TVIHDt2TFJTU+V3v/udxMfH6019/ec//1mOHj3qz6HBQydPFcmWXXsl+f7+EtU0TBwOQ+64qZt0vyxGIpuESrPwEGkQHCgT7+0nGz79WgaOmidrPt4lbz5/n/SKa8t1Rq0RHBwil1/RRV5atECOHMnRoeL9te/Jv3ftlKNHj/h7eLCa4aOtGvJbkMjIyJD27dvLnDlzJCwsTHr37q039bXaFxsbK9u3b//NzykqKpL8/Hy3zVVWWiXfA34xYvIyUUF57//MkLyts2X0nX3k7XXbpazMJQ7HL/8n9v4nX8jc1z+Wf393UJ5bukH+8c+v5P5benEJUavMSEkVl8sl/a7rLd26dJblr70qN940oOLfCVAT+W2y5ZgxY+TWW2+VRYsWnVWuUf/QHnroIf2e9PT0835OSkqKPPXUU2776kR0k4CoqywZN86m5jzccN+LUj+wnoSGBEr2sXx5dea9su/gMTl2/KSUlJTKN3sPu/2dzL3Z0rPLRVxO1CqtoqPlb6+8JqdOndIrONSEy0mPjpeWLVv5e2iwmFFN2xK+4LcYvGvXLpkwYUKlF1ftU8d27tz5m5+TnJwseXl5blvdiDiLRo3zOVVYrENEwwZBktCzo65ClJwulR1f/yjtW7vPSG/XuplkHWbpJ2qn+vXr6xCRn5cn6f/aLNded72/hwSLGTaeI+G3ikRkZKRs27ZNtzAqo455shxKTVT69eQlw1HHZ+PEb0uI76hbG9/9cEQubtVUnpkwWL7blyPL1vxSTZr1yofy6rMjZPNne2Tj9u/khp6d5Kbel0ri/S9yeVGr/GvzP1XJVVrHxMj+rCyZ9VyqtIm5SAb9boi/hwaLGdUzA9TsIDFx4kR54IEHZMeOHXL99ddXhIacnBxJS0uTxYsXy3PPPeev4cELYSGB8qcxN0uLiIbyU94peS9tpzw5f62cPl2mj6/5+N8yZsabMmnEDfL8Y7fIdz8ekTsn/VU+3bmX64xa5eTJEzJn9guSk50tYWEN5fp+N8iYcRMkICDA30MDTDNcakKCn7z11lsya9YsHSbUDGalTp06EhcXJ0lJSXLbbbeZ+tygLo/4eKSAPRzPmOfvIQDVTmAV/ErdbtI6n3zO7j/fKNWNX+9sefvtt+utpKRELwVVmjRpQjoHANiKQWvDWqqsFxUVZfFZAACAr/GsDQAALGbYuCRBkAAAwGKGfXMEz9oAAADmUZEAAMBiDod9SxIECQAALGbYN0fQ2gAAAOZRkQAAwGKGjUsSPLsWAACLGYZvNm+0adOm0gd/jR49Wh8vLCzUXzdu3FhCQkJk6NCh+jEV3iJIAABgw6d/ZmRkyOHDhyu2DRs26P233nqr/lM9ZXvt2rWyYsUK2bhxoxw6dEiGDPH+AXK0NgAAsKGmTZu6vZ45c6ZcfPHF0qdPH8nLy5MlS5bI8uXLpW/fvvr40qVLpWPHjrJlyxbp0aOHx+ehIgEAQA2pSBQVFUl+fr7bpvb9luLiYnnttddkxIgR+nPUwzLVc64SEhIq3hMbGyvR0dGSnp7u1fdGkAAAoIbMkUhJSZGwsDC3Te37LatXr5bc3Fy555579Ovs7GypV6+eNGzY0O19ERER+pg3aG0AAFBDJCcnS1JSkts+p9P5m39PtTH69+8vzZs39/mYCBIAANSQ5Z9Op9Oj4HCmH3/8UT788EN59913K/ZFRkbqdoeqUpxZlVCrNtQxb9DaAADAhss/y6lJlM2aNZMBAwZU7IuLi5OAgABJS0ur2JeZmSlZWVkSHx8v3qAiAQCATZWVlekgMXz4cKlb9/9/5Ku5FSNHjtRtkvDwcAkNDZUxY8boEOHNig2FIAEAgE3vbPnhhx/qKoNarfFrs2bNEofDoW9EpVZ+JCYmyoIFC7w+h+FyuVxiM0FdHvH3EIBq6XjGPH8PAah2AqvgV+qu0z/2yedsn3ydVDfMkQAAAKbR2gAAwGKGjR/aRZAAAMBihn1zBEECAACrGTZOEsyRAAAAptHaAADAYoZ9CxIECQAArGbYOEnQ2gAAAKbR2gAAwGKGfQsSBAkAAKxm2DhJ0NoAAACm0doAAMBihn0LEgQJAACsZtg4SdDaAAAAptHaAADAYoaNKxIECQAALGbYN0cQJAAAsJph4yTBHAkAAGAarQ0AACxm2LcgQZAAAMBqho2TBK0NAABgGq0NAAAsZti3IEGQAADAag4bJwlaGwAAwDRaGwAAWMywb0GCIAEAgNUMGycJKhIAAFjMYd8cwRwJAABgHhUJAAAsZtDaAAAA5oOE2BbLPwEAgGkECQAALGb46H/eOnjwoNx1113SuHFjCQoKks6dO8v27dsrjrtcLpk6dapERUXp4wkJCbJ7926vzkGQAACgClZtOHyweeP48eNy9dVXS0BAgHzwwQfy9ddfy/PPPy+NGjWqeE9qaqrMmTNHFi1aJFu3bpXg4GBJTEyUwsJCj8/DZEsAAGzo2WeflVatWsnSpUsr9sXExLhVI2bPni2TJ0+WQYMG6X3Lli2TiIgIWb16tdxxxx0enYeKBAAAVbBqw/DBVlRUJPn5+W6b2leZNWvWSNeuXeXWW2+VZs2aSZcuXWTx4sUVx/ft2yfZ2dm6nVEuLCxMunfvLunp6R5/bwQJAACqYNWG4YMtJSVF/7A/c1P7KrN3715ZuHChtGvXTtavXy+jRo2SsWPHyiuvvKKPqxChqArEmdTr8mOeoLUBAEANkZycLElJSW77nE5npe8tKyvTFYlnnnlGv1YViS+//FLPhxg+fLjPxkRFAgCAKniMuMMHmwoNoaGhbtu5goRaidGpUye3fR07dpSsrCz9dWRkpP4zJyfH7T3qdfkxj743E9cDAAD4obXhDbViIzMz023fd999J61bt66YeKkCQ1paWsVxNedCrd6Ij4/3+Dy0NgAAsOEtsidMmCA9e/bUrY3bbrtNtm3bJi+99JLeysc0fvx4mT59up5HoYLFlClTpHnz5jJ48GCPz0OQAADAhrp16yarVq3S8yr+9Kc/6aCglnsOGzas4j2PPfaYFBQUyAMPPCC5ubnSq1cvWbdunQQGBnp8HsOlFpLaTFCXR/w9BKBaOp4xz99DAKqdwCr4lfrWlz/zyeesuOdKqW6oSAAAYDGHjZ/axWRLAABgGhUJAAAsZtj4ChMkAACw4aqNqkJrAwAAmEZFAgAAiznsW5AgSAAAYDXDxq0NjyoS6lGknrr55psvZDwAAMBuQcLTW2WqxFVaWnqhYwIAwFYMo5YHCfUoUgAAYI5h4yTBZEsAACzmsG+OMBck1AM+Nm7cqJ9pXlxc7HZs7NixvhobAACwW5D4/PPP5aabbpJTp07pQBEeHi7Hjh2T+vXrS7NmzQgSAADUotaGw8zzzQcOHCjHjx+XoKAg2bJli/z4448SFxcnzz33nDWjBACgBjN8tNkiSOzcuVMeffRRcTgcUqdOHSkqKpJWrVpJamqq/PGPf7RmlAAAwB5BIiAgQIcIRbUy1DwJJSwsTPbv3+/7EQIAYIPHiDt8sNlijkSXLl0kIyND2rVrJ3369JGpU6fqORKvvvqqXHrppdaMEgCAGsyonhnAPxWJZ555RqKiovTXM2bMkEaNGsmoUaPk6NGj8tJLL1kxRgAAUE15XZHo2rVrxdeqtbFu3TpfjwkAAFsxbFyS4IZUAABYzLBvjvA+SMTExJw3We3du/dCxwQAAOwaJMaPH+/2uqSkRN+kSrU4Jk2a5MuxAQBgCw4blyS8DhLjxo2rdP/8+fNl+/btvhgTAAC2Ytg3R3i/auNc+vfvLytXrvTVxwEAYBuGYfhks3WQeOedd/RzNwAAQO1h6oZUZ6Yil8sl2dnZ+j4SCxYskOoga9Nsfw8BqJaGLdvh7yEA1c7KEXE157d2OwSJQYMGuQUJdbvspk2byrXXXiuxsbG+Hh8AADWeUU3bEn4JEtOmTbNmJAAAoMbxutqinvh55MiRs/b/5z//0ccAAIA7h+GbzRYVCTUnojLqceL16tXzxZgAALAVRzUNAVUaJObMmVPR5/nrX/8qISEhFcdKS0tl06ZNzJEAAKCW8ThIzJo1q6IisWjRIrc2hqpEtGnTRu8HAAC1Z7Klx3Mk9u3bp7c+ffrIrl27Kl6rLTMzU9avXy/du3e3drQAANRADj/MkVCLI359Q6szV1cWFhbK6NGjpXHjxrrLMHToUMnJyfH+e/P2L3z88cfSqFEjr08EAACq1iWXXCKHDx+u2DZv3lxxbMKECbJ27VpZsWKFbNy4UQ4dOiRDhgyxfrKlSixXXXWVPP744277U1NTJSMjQw8IAAD8P391NurWrSuRkZFn7c/Ly5MlS5bI8uXLpW/fvnrf0qVLpWPHjrJlyxbp0aOHdRUJNanypptuqvRZG+oYAAA4++mfvtjUCsn8/Hy3Te07l927d0vz5s3loosukmHDhklWVpbev2PHDv307oSEhIr3qrZHdHS0pKenize8DhInT56sdJlnQECA/oYAAMDZP2x9saWkpEhYWJjbpvZVRs1bfPnll2XdunWycOFCPafxmmuukRMnTuhHW6if5Q0bNnT7OxEREfqYpa2Nzp07y1tvvSVTp0512//mm29Kp06dvP04AADgoeTkZElKSnLb53Q6K32v6hSUu+yyy3SwaN26tbz99tsSFBQkvuJ1kJgyZYqejPH9999X9FXS0tJ0n0U9ARQAAFgzR0KFhnMFh9+iqg/t27eXPXv2SL9+/aS4uFhyc3PdqhJq1UZlcyp82toYOHCgrF69Wg/k4YcflkcffVQOHjwoH330kbRt29bbjwMAwPYcPpojcSHU1ARVBIiKipK4uDg9JUEVAsqpWzmoORTx8fHWViSUAQMG6E1R8yLeeOMNmThxop68oe5yCQAA/Ev9XFa//Kt2hlra+eSTT+qbSd555516bsXIkSN1myQ8PFxCQ0NlzJgxOkR4s2LDdJBQ1AoNtXRk5cqVekaoanfMnz/f7McBAGBbhh+Wfx44cECHBvVQzaZNm0qvXr300k71dfkdqx0Oh76tg1r5kZiYKAsWLPD6PF4FCTWTU80AVQFCVSJuu+02fXLV6mCiJQAA1eehXWoRxPkEBgbqAsCFFgE8niOhyiMdOnSQf//73zJ79mxdJpk7d+4FnRwAANRsHlckPvjgAxk7dqyMGjVK2rVrZ+2oAACwEQcP7RJ9f251Ews101OtRZ03b54cO3bM3/9tAACo9gzDN1t15HFrQ83iXLx4sX7ox4MPPqh7L2qSZVlZmWzYsEGHDAAAULt4fR+J4OBgGTFihK5QfPHFF/o+EjNnzpRmzZrJzTffbM0oAQCowRx+eIx4tQ0SZ1KTL9VTP9USE3UvCQAAcDbDR/+rjkzfR+JM6gYXgwcP1hsAAHBXXasJfq9IAACA2s0nFQkAAFA7KxIECQAALGZU17WbPkBrAwAAmEZFAgAAiznsW5AgSAAAYDXDxkGC1gYAADCN1gYAABZz2LgkQZAAAMBiDvvmCFobAADAPCoSAABYzLBxRYIgAQCAxRzV9IFbvkCQAADAYoZ9cwRzJAAAgHlUJAAAsJjDxhUJggQAABZz2Li3wZ0tAQCAaVQkAACwmGHfggRBAgAAqzlsnCRobQAAANNobQAAYDHDvgUJggQAAFZz2PgS2/l7AwAAFqO1AQCAxQwb9zaoSAAAYDHDR9uFmDlzpg4048ePr9hXWFgoo0ePlsaNG0tISIgMHTpUcnJyvPpcggQAAFWw/NPhg82sjIwM+ctf/iKXXXaZ2/4JEybI2rVrZcWKFbJx40Y5dOiQDBkyxLvvzfSoAABAtXfy5EkZNmyYLF68WBo1alSxPy8vT5YsWSIvvPCC9O3bV+Li4mTp0qXy6aefypYtWzz+fIIEAAA1pLVRVFQk+fn5bpvadz6qdTFgwABJSEhw279jxw4pKSlx2x8bGyvR0dGSnp7u8fdGkAAAwGKG4ZstJSVFwsLC3Da171zefPNN+eyzzyp9T3Z2ttSrV08aNmzotj8iIkIf8xSrNgAAqCGSk5MlKSnJbZ/T6az0vfv375dx48bJhg0bJDAw0LIxESQAAKghyz+dTuc5g8OvqdbFkSNH5Morr6zYV1paKps2bZJ58+bJ+vXrpbi4WHJzc92qEmrVRmRkpMdjIkgAAGAxhx+u8PXXXy9ffPGF2757771Xz4N4/PHHpVWrVhIQECBpaWl62aeSmZkpWVlZEh8f7/F5CBIAANhQgwYN5NJLL3XbFxwcrO8ZUb5/5MiRulUSHh4uoaGhMmbMGB0ievTo4fF5CBIAANTSO1vOmjVLHA6Hrkio1R+JiYmyYMECrz7DcLlcLrGZoydO+3sIQLX00Ipd/h4CUO2sHBFn+TlW7Dzkk8+59YrmUt2w/BMAAJhGawMAgFra2vAFggQAABZz2PgKEyQAALCYYeOKhJ1DEgAAsBgVCQAALGbY+AoTJAAAsJhh4yRBawMAAJhGRQIAAIs5bNzcIEgAAGAxw745gtYGAAAwj4oEAAAWM2htAAAA00HCsO+1Y9UGAAAwjdYGAAAWc9DaAAAAZhk2bm1QkQAAwGKGjYMEcyQAAIBpVCQAALCYwRwJAABgloPWBgAAwNlobQAAYDGD1gYAADAdJAz7XjtWbQAAANNobQAAYDGD1gYAADDLQWsDAADgbLQ2cMF2frZdlr/6N8n85mv5z7Gj8sxzc6T3tddXHJ8x7Y/ywfvvuf2dq+KvlhfmvsTVh23d1iVKbu/S3G3fwdxCGfvuV/rriAb1ZPhVLSW2WYgE1HHIzoN58tf0/ZJXeNpPI4aVDFobwLn9/PPP0rZdBxlw8xD570njKn1P95695I9Tp1e8DqhXj0sK28s6/rM8te67itelZS79p7OuQ6Ymtpcffjol0/7v+J1XtpDkfm0lee238su7YCeGjVsbVCRwweKvvkZv51MvoJ40btKUq41aRQWH3J/PrjDENguWpiH1ZOJ7X8vPJWV639xN++SVu66Qzs0byL8PnfDDaGElw8aXlyCBKvH5jgz5r37XSIMGoRLXrbvcP2qshDVsyNWHrUWFOmXxHZ2lpNQlmUdOyuvbD8qxghLdylDU/nLFpS5xuURiI0IIEqhRanyQKCoq0pvbvuI64nQ6/TYmuOse30v6XJcgUS1aysED++Wl+bNl4tgHZdHS5VKnTh0uF2xp99ECmffPH+RQXpE0qh8gt14RJdMHdJDx734t3x0tkMLTZfKHbi10uDAMQ+7q2kLqOAxpFBTg76HDAg4b9zaq9Q2p9u/fLyNGjDjve1JSUiQsLMxte/H5Z6tsjPhtCYk3Sa8+feXitu31JMxnZy2Qb77+UlcpALv6/EC+pP+QKz8e/1l2HsyXGRv2SP16deXqmEaSX3hanv/oe+naqqG8fncXefWuKyS4Xh35/liBrkrAfgwfbd5YuHChXHbZZRIaGqq3+Ph4+eCDDyqOFxYWyujRo6Vx48YSEhIiQ4cOlZycHHsFiZ9++kleeeWV874nOTlZ8vLy3LZxjz5eZWOE91q0bCUNGzaSA/uzuHyoNU4Vl8rhvEKJDP2lWrrr0AkZ/c6XMmL5Lrln+S6Zs+kHCa9fT3JOuFdYAbNatmwpM2fOlB07dsj27dulb9++MmjQIPnqq19WDk2YMEHWrl0rK1askI0bN8qhQ4dkyJAhNau1sWbNmvMe37t3729+hmph/LqNUXSC5VPV2ZGcbMnLy5UmTZr4eyhAlQms65CIUKcc/77Ebf+JolL956VRDSQsqK5kZOXyX8WOjKo/5cCBA91ez5gxQ1cptmzZokPGkiVLZPny5TpgKEuXLpWOHTvq4z169KgZQWLw4MG6N+g6Ty1PHUf1dupUgRw8o7pw+OAB2Z35jTQIC5PQ0DBZunih9OnbTxo3bqLnSCyY87y0aBUtV8X38uu4ASvd3a2FbN+fJ0dPFkt4/QB9T4myMpds3ntcH7+uXWM5kFso+YUl0qFZiIzo3kre/+qIHMqnImFHho+SRGXzAiv7hfrXSktLdeWhoKBAtzhUlaKkpEQSEhIq3hMbGyvR0dGSnp5ec4JEVFSULFiwQJdaKrNz506Ji4ur8nHBO99+/ZWMfejeitdzZ6XqP/v/1yCZ+MRU+X53pr4h1ckT+dKkaTPp1qOn3P/QGKnHvSRgY42D68mEa2OkgbOunhPxTc5JSX7/W/210iIsUIbFtZAQZx0dNlbuOixrvzri72GjmktJSZGnnnrKbd+TTz4p06ZNq/T9X3zxhQ4Oaj6EmgexatUq6dSpk/75qv5/cMNfrZ6LiIiQ7Oxsr8bk1yChQoJKRecKEr9VrUD1cGXXq2Tz9l96bpV5Yd7iKh0PUB3M+mTfeY+/tv2g3lA7GD4qrqt5gUlJSW77zleN6NChgw4Nav7gO++8I8OHD9fzIXzJr0Fi0qRJusxyLm3btpWPP/64SscEAICvGT76HE/aGGdSVQf1s7T8l/eMjAx58cUX5fbbb5fi4mLJzc11q0qoVRuRkZE1Z9XGNddcIzfeeOM5jwcHB0ufPn2qdEwAANhVWVmZnmOhQkVAQICkpaVVHMvMzJSsrCzdCqlVN6QCAKDaM6r+lKoN0r9/fz2B8sSJE3qFxieffCLr16/X91waOXKkbpOEh4fr+0yMGTNGhwhvJloqBAkAAGz49M8jR47I3XffLYcPH9bBQd2cSoWIfv366eOzZs0Sh8Ohb0SlqhSJiYl6AYS3DJcNZzMe5T4SQKUeWrGLKwP8ysoR1q8O3PFDvk8+J65NqFQ31frOlgAAoHqjtQEAgMUMG19hggQAAFYz7HuJaW0AAADTqEgAAGDDVRtVhSABAIDFDPvmCFobAADAPCoSAABYzLDxFSZIAABgNcO+l5hVGwAAwDQqEgAAWMywcUmCIAEAgMXsvGqDIAEAgMUMG19h5kgAAADTqEgAAGA1w76XmCABAIDFDBsnCVobAADANCoSAABYzLBvQYIgAQCA1QwbX2JaGwAAwDRaGwAAWM2w7yUmSAAAYDHDxkmC1gYAADCNigQAABYz7FuQIEgAAGA1w8aXmIoEAABWM+x7iZkjAQAATKMiAQCAxQwblyQIEgAAWMywb46gtQEAAMyjIgEAgMUMG19hJlsCAFAVScLwweaFlJQU6datmzRo0ECaNWsmgwcPlszMTLf3FBYWyujRo6Vx48YSEhIiQ4cOlZycHK/OQ5AAAMCGNm7cqEPCli1bZMOGDVJSUiI33HCDFBQUVLxnwoQJsnbtWlmxYoV+/6FDh2TIkCFencdwuVwusZmjJ077ewhAtfTQil3+HgJQ7awcEWf5OfYeLfTJ51zUNND03z169KiuTKjA0Lt3b8nLy5OmTZvK8uXL5ZZbbtHv+fbbb6Vjx46Snp4uPXr08OhzqUgAAFAFqzYMH2xFRUWSn5/vtql9nlDBQQkPD9d/7tixQ1cpEhISKt4TGxsr0dHROkh4iiABAEANkZKSImFhYW6b2vdbysrKZPz48XL11VfLpZdeqvdlZ2dLvXr1pGHDhm7vjYiI0Mc8xaoNAABqyKqN5ORkSUpKctvndDp/8++puRJffvmlbN68WXyNIAEAQA1JEk6n06PgcKZHHnlE3n//fdm0aZO0bNmyYn9kZKQUFxdLbm6uW1VCrdpQxzxFawMAgCq4Rbbhg/95Q62lUCFi1apV8tFHH0lMTIzb8bi4OAkICJC0tLSKfWp5aFZWlsTHx3t8HioSAADY0OjRo/WKjPfee0/fS6J83oOaVxEUFKT/HDlypG6VqAmYoaGhMmbMGB0iPF2xoRAkAACw4bM2Fi5cqP+89tpr3fYvXbpU7rnnHv31rFmzxOFw6BtRqdUfiYmJsmDBAq/Ow30kgFqE+0gA/rmPxP6fPFui+VtahXs3P6IqMEcCAACYRmsDAACLGTZ+ahdBAgAAyxm2vca0NgAAgGlUJAAAsJhh34IEQQIAAKsZNr7EtDYAAIBptDYAALCYYeOSBEECAACLGTZubhAkAACwmmHfS8wcCQAAYBoVCQAALGbY+AoTJAAAsJhh4yRBawMAAJhGRQIAAIsZNm5uECQAALCaYd9LTGsDAACYRkUCAACLGTa+wgQJAAAsZtg4SdDaAAAAplGRAADAYoaNmxsECQAALGbYN0fQ2gAAAOYxRwIAAJhGawMAAIsZNm5tECQAALCYYePJlrQ2AACAaVQkAACwmGHfggRBAgAAqxk2vsS0NgAAgGm0NgAAsJph30tMkAAAwGKGjZMErQ0AAGxq06ZNMnDgQGnevLkYhiGrV692O+5yuWTq1KkSFRUlQUFBkpCQILt37/bqHAQJAACqYNWG4YPNWwUFBXL55ZfL/PnzKz2empoqc+bMkUWLFsnWrVslODhYEhMTpbCw0ONz0NoAAMBiho8+p6ioSG9ncjqdeqtM//799VYZVY2YPXu2TJ48WQYNGqT3LVu2TCIiInTl4o477vBoTFQkAACoiiRhXPiWkpIiYWFhbpvaZ8a+ffskOztbtzPKqc/r3r27pKene/w5VCQAAKghkpOTJSkpyW3fuaoRv0WFCEVVIM6kXpcf8wRBAgCAGrJqw3meNoa/0NoAAMCmky3PJzIyUv+Zk5Pjtl+9Lj/mCYIEAAC1UExMjA4MaWlpFfvy8/P16o34+Pja3dpo2sCW31aNo2YWq0lAqqdX3UpxtdXKEXH+HgL4t1ErBfrpx9LJkydlz549bhMsd+7cKeHh4RIdHS3jx4+X6dOnS7t27XSwmDJlir7nxODBgz0+h+FS6z8AC6hkq2YA5+XlSWhoKNcY4N8Gqtgnn3wi11133Vn7hw8fLi+//LJeAvrkk0/KSy+9JLm5udKrVy9ZsGCBtG/f3uNzECRgGYIEwL8N2B9zJAAAgGkECQAAYBpBApZREyxV742JlgD/NmBfzJEAAACmUZEAAACmESQAAIBpBAkAAGAaQQIAAJhGkIBl5s+fL23atJHAwED9fPtt27ZxtVGrbdq0SQYOHKhvQWwYhqxevdrfQwIuGEEClnjrrbckKSlJL//87LPP5PLLL5fExEQ5cuQIVxy1VkFBgf63oEI2YBcs/4QlVAWiW7duMm/ePP26rKxMWrVqJWPGjJEnnniCq45aT1UkVq1a5dXDkYDqiIoEfK64uFh27NghCQkJ//9/aA6Hfp2ens4VBwAbIUjA544dOyalpaUSERHhtl+9zs7O5ooDgI0QJAAAgGkECfhckyZNpE6dOpKTk+O2X72OjIzkigOAjRAk4HP16tWTuLg4SUtLq9inJluq1/Hx8VxxALCRuv4eAOxJLf0cPny4dO3aVa666iqZPXu2Xvp27733+ntogN+cPHlS9uzZU/F63759snPnTgkPD5fo6Gj+y6BGYvknLKOWfv75z3/WEyyvuOIKmTNnjl4WCtRWn3zyiVx33XVn7Veh++WXX/bLmIALRZAAAACmMUcCAACYRpAAAACmESQAAIBpBAkAAGAaQQIAAJhGkAAAAKYRJAAAgGkECQAAYBpBArChe+65RwYPHlzx+tprr5Xx48f75U6OhmFIbm5ulZ8bQNUgSABV/ANe/WBVm3q4Wdu2beVPf/qTnD592tLzvvvuu/L000979F5++APwBg/tAqrYjTfeKEuXLpWioiL5xz/+IaNHj5aAgABJTk52e19xcbEOG76gHgoFAFagIgFUMafTKZGRkdK6dWsZNWqUJCQkyJo1ayraETNmzJDmzZtLhw4d9Pv3798vt912mzRs2FAHgkGDBskPP/xQ8XmlpaX6aavqeOPGjeWxxx4Tl8vlds5ftzZUiHn88celVatWejyqMrJkyRL9ueUPlWrUqJGunKhxlT8KPiUlRWJiYiQoKEguv/xyeeedd9zOo4JR+/bt9XH1OWeOE4A9ESQAP1M/dFX1QUlLS5PMzEzZsGGDvP/++1JSUiKJiYnSoEED+ec//yn/+te/JCQkRFc1yv/O888/r58c+be//U02b94sP/30k6xateq857z77rvljTfe0E9k/eabb+Qvf/mL/lwVLFauXKnfo8Zx+PBhefHFF/VrFSKWLVsmixYtkq+++komTJggd911l2zcuLEi8AwZMkQGDhyoH4193333yRNPPGHx1QPgdy4AVWb48OGuQYMG6a/LyspcGzZscDmdTtfEiRP1sYiICFdRUVHF+1999VVXhw4d9HvLqeNBQUGu9evX69dRUVGu1NTUiuMlJSWuli1bVpxH6dOnj2vcuHH668zMTFWu0OeuzMcff6yPHz9+vGJfYWGhq379+q5PP/3U7b0jR4503Xnnnfrr5ORkV6dOndyOP/7442d9FgB7YY4EUMVUpUH99q+qDapd8Pvf/16mTZum50p07tzZbV7Erl27ZM+ePboicabCwkL5/vvvJS8vT1cNunfvXnGsbt260rVr17PaG+VUtaBOnTrSp08fj8esxnDq1Cnp16+f235VFenSpYv+WlU2zhyHEh8f7/E5ANRMBAmgiqm5AwsXLtSBQc2FUD/4ywUHB7u99+TJkxIXFyevv/76WZ/TtGlT060Ub6lxKH//+9+lRYsWbsfUHAsAtRdBAqhiKiyoyY2euPLKK+Wtt96SZs2aSWhoaKXviYqKkq1bt0rv3r31a7WUdMeOHfrvVkZVPVQlRM1tUBM9f628IqImcZbr1KmTDgxZWVnnrGR07NhRTxo905YtWzz6PgHUXEy2BKqxYcOGSZMmTfRKDTXZct++ffo+D2PHjpUDBw7o94wbN05mzpwpq1evlm+//VYefvjh894Aqk2bNjJ8+HAZMWKE/jvln/n222/r42o1iVqtoVowR48e1dUI1VqZOHGinmD5yiuv6LbKZ599JnPnztWvlYceekh2794tkyZN0hM1ly9frieBArA3ggRQjdWvX182bdok0dHRekWE+q1/5MiReo5EeYXi0UcflT/84Q86HKg5CeqH/u9+97vzfq5qrdxyyy06dMTGxsr9998vBQUF+phqXTz11FN6xUVERIQ88sgjer+6odWUKVP06g01DrVyRLU61HJQRY1RrfhQ4UQtDVWrO5555hnLrxEA/zLUjEs/jwEAANRQVCQAAIBpBAkAAGAaQQIAAJhGkAAAAKYRJAAAgGkECQAAYBpBAgAAmEaQAAAAphEkAACAaQQJAABgGkECAACIWf8LHq9DBpWp+uIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "importances = pd.Series(best_rf.feature_importances_, index=X_train.columns)\n",
    "print(importances.sort_values(ascending=True).head(40))\n",
    "importances.nlargest(10).plot(kind='barh')\n",
    "plt.title('-10     Random Forest')\n",
    "plt.show()\n",
    "\n",
    "errors_df = val_df_raw.copy()\n",
    "errors_df['Actual'] = val_df_raw['Survived']\n",
    "errors_df['Predicted'] = final_model.predict(X_val)\n",
    "errors = errors_df[errors_df['Actual'] != errors_df['Predicted']]\n",
    "errors.head(10)\n",
    "\n",
    "y_probs = final_model.predict_proba(X_val)[:, 1]\n",
    "y_pred_custom = (y_probs >= 0.5).astype(int)\n",
    "sns.heatmap(confusion_matrix(y_val, y_pred_custom), annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
