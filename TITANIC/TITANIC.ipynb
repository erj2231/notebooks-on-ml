{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okut-YZtQXC8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\system\\python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-12-29 16:52:12,796] A new study created in memory with name: no-name-f44b1f8a-4408-4057-a4b2-8d3bd49b9be9\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:52:19,551] Trial 0 finished with value: 0.8356840342755835 and parameters: {'n_estimators': 167, 'max_depth': 10, 'learning_rate': 0.039128384299913624, 'subsample': 0.7454220914936434, 'colsample_bytree': 0.5440330206362676, 'weight_rf': 0.3450200483828529, 'weight_xgb': 0.8509842430854809}. Best is trial 0 with value: 0.8356840342755835.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:52:27,559] Trial 1 finished with value: 0.8427656850192061 and parameters: {'n_estimators': 487, 'max_depth': 6, 'learning_rate': 0.02583195472787213, 'subsample': 0.9011156259396338, 'colsample_bytree': 0.9253218258642006, 'weight_rf': 0.6657524352406125, 'weight_xgb': 0.7973242529477297}. Best is trial 1 with value: 0.8427656850192061.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:52:34,083] Trial 2 finished with value: 0.8469023933812666 and parameters: {'n_estimators': 217, 'max_depth': 6, 'learning_rate': 0.022786448349557436, 'subsample': 0.6182203926115611, 'colsample_bytree': 0.612448963250843, 'weight_rf': 0.44472840917801193, 'weight_xgb': 0.3142708044229293}. Best is trial 2 with value: 0.8469023933812666.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:52:41,494] Trial 3 finished with value: 0.8328966807840047 and parameters: {'n_estimators': 323, 'max_depth': 8, 'learning_rate': 0.061462297620903446, 'subsample': 0.7555676368201083, 'colsample_bytree': 0.7478480883814097, 'weight_rf': 0.2768872473350359, 'weight_xgb': 0.4280656282318276}. Best is trial 2 with value: 0.8469023933812666.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:52:48,851] Trial 4 finished with value: 0.8426770412685907 and parameters: {'n_estimators': 218, 'max_depth': 7, 'learning_rate': 0.011629429560611871, 'subsample': 0.7041896949653443, 'colsample_bytree': 0.6470239572069458, 'weight_rf': 0.8286103043941139, 'weight_xgb': 0.5240062008052677}. Best is trial 2 with value: 0.8469023933812666.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:52:56,454] Trial 5 finished with value: 0.8399192356938835 and parameters: {'n_estimators': 364, 'max_depth': 8, 'learning_rate': 0.055822115412036744, 'subsample': 0.9445957172533207, 'colsample_bytree': 0.7323287504198056, 'weight_rf': 0.9687638401950784, 'weight_xgb': 0.39219956699169456}. Best is trial 2 with value: 0.8469023933812666.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:52:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:53:02,320] Trial 6 finished with value: 0.8469319412981384 and parameters: {'n_estimators': 61, 'max_depth': 5, 'learning_rate': 0.09992523109715036, 'subsample': 0.7293375945521918, 'colsample_bytree': 0.9716580540379303, 'weight_rf': 0.6173897530212962, 'weight_xgb': 0.5831367656439921}. Best is trial 6 with value: 0.8469319412981384.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:53:09,634] Trial 7 finished with value: 0.8314980793854033 and parameters: {'n_estimators': 334, 'max_depth': 10, 'learning_rate': 0.03355000128615936, 'subsample': 0.7941131726112866, 'colsample_bytree': 0.5888501167854572, 'weight_rf': 0.23378091129425768, 'weight_xgb': 0.7151160632381778}. Best is trial 6 with value: 0.8469319412981384.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:53:16,271] Trial 8 finished with value: 0.8440953412784399 and parameters: {'n_estimators': 389, 'max_depth': 4, 'learning_rate': 0.028062318188954712, 'subsample': 0.5251261178773677, 'colsample_bytree': 0.8764125286064195, 'weight_rf': 0.259765816907674, 'weight_xgb': 0.19672022126184818}. Best is trial 6 with value: 0.8469319412981384.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:53:24,022] Trial 9 finished with value: 0.8455234905939133 and parameters: {'n_estimators': 443, 'max_depth': 8, 'learning_rate': 0.011391071250194586, 'subsample': 0.8468907077214844, 'colsample_bytree': 0.8381461036269084, 'weight_rf': 0.3435150775314899, 'weight_xgb': 0.15092245734015514}. Best is trial 6 with value: 0.8469319412981384.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:53:29,609] Trial 10 finished with value: 0.8454840933714174 and parameters: {'n_estimators': 60, 'max_depth': 3, 'learning_rate': 0.08415907166813717, 'subsample': 0.6173383166802269, 'colsample_bytree': 0.987066183702667, 'weight_rf': 0.602626664606787, 'weight_xgb': 0.9945282693118902}. Best is trial 6 with value: 0.8469319412981384.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:53:35,300] Trial 11 finished with value: 0.8412685905643652 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.016867228589260697, 'subsample': 0.6377101753036508, 'colsample_bytree': 0.6382454962021344, 'weight_rf': 0.4731030954064024, 'weight_xgb': 0.29701879591206537}. Best is trial 6 with value: 0.8469319412981384.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:53:41,295] Trial 12 finished with value: 0.8497094454840933 and parameters: {'n_estimators': 162, 'max_depth': 5, 'learning_rate': 0.018446937275239068, 'subsample': 0.5017357490642349, 'colsample_bytree': 0.6965080177165731, 'weight_rf': 0.4757244457393536, 'weight_xgb': 0.6033432414673741}. Best is trial 12 with value: 0.8497094454840933.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:53:47,292] Trial 13 finished with value: 0.8440953412784399 and parameters: {'n_estimators': 155, 'max_depth': 4, 'learning_rate': 0.017286871280503442, 'subsample': 0.5022649185008091, 'colsample_bytree': 0.7904970560665324, 'weight_rf': 0.7373388136578025, 'weight_xgb': 0.5919261341410641}. Best is trial 12 with value: 0.8497094454840933.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:53:53,592] Trial 14 finished with value: 0.8455037919826651 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.09280643670521707, 'subsample': 0.5658806696834924, 'colsample_bytree': 0.6929507930114625, 'weight_rf': 0.5235857877840061, 'weight_xgb': 0.6252671894698962}. Best is trial 12 with value: 0.8497094454840933.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:53:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:54:00,102] Trial 15 finished with value: 0.8440854919728158 and parameters: {'n_estimators': 247, 'max_depth': 3, 'learning_rate': 0.04573062407474999, 'subsample': 0.6756018624977715, 'colsample_bytree': 0.9897820535801923, 'weight_rf': 0.7666932908930676, 'weight_xgb': 0.481970196164065}. Best is trial 12 with value: 0.8497094454840933.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:54:06,423] Trial 16 finished with value: 0.8426967398798386 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.019934644030216286, 'subsample': 0.8300330511161199, 'colsample_bytree': 0.8123019044122588, 'weight_rf': 0.12628370807783823, 'weight_xgb': 0.6554660879228867}. Best is trial 12 with value: 0.8497094454840933.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:54:12,703] Trial 17 finished with value: 0.8426868905742145 and parameters: {'n_estimators': 162, 'max_depth': 4, 'learning_rate': 0.013175295640963173, 'subsample': 0.9801060737698769, 'colsample_bytree': 0.9072375585536591, 'weight_rf': 0.6396993859461662, 'weight_xgb': 0.7745901817328925}. Best is trial 12 with value: 0.8497094454840933.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:54:19,183] Trial 18 finished with value: 0.8483305426967398 and parameters: {'n_estimators': 106, 'max_depth': 7, 'learning_rate': 0.07556334806922411, 'subsample': 0.5663221285373815, 'colsample_bytree': 0.513192671611381, 'weight_rf': 0.9375336198412894, 'weight_xgb': 0.8959533997605617}. Best is trial 12 with value: 0.8497094454840933.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:54:25,365] Trial 19 finished with value: 0.8469023933812665 and parameters: {'n_estimators': 108, 'max_depth': 7, 'learning_rate': 0.06942797918185072, 'subsample': 0.5691115794567083, 'colsample_bytree': 0.5129690497331659, 'weight_rf': 0.9662380947965837, 'weight_xgb': 0.956537410381494}. Best is trial 12 with value: 0.8497094454840933.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:54:32,396] Trial 20 finished with value: 0.8399093863882596 and parameters: {'n_estimators': 280, 'max_depth': 9, 'learning_rate': 0.047940377227970135, 'subsample': 0.5566047360569899, 'colsample_bytree': 0.689859395135539, 'weight_rf': 0.8912011123342828, 'weight_xgb': 0.8373712970537113}. Best is trial 12 with value: 0.8497094454840933.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:54:37,918] Trial 21 finished with value: 0.848300994779868 and parameters: {'n_estimators': 57, 'max_depth': 6, 'learning_rate': 0.09792832925105557, 'subsample': 0.5032288294657846, 'colsample_bytree': 0.5603538019889976, 'weight_rf': 0.43710458296345944, 'weight_xgb': 0.6827145911026656}. Best is trial 12 with value: 0.8497094454840933.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:54:43,569] Trial 22 finished with value: 0.8567320003939722 and parameters: {'n_estimators': 97, 'max_depth': 6, 'learning_rate': 0.07602690602356578, 'subsample': 0.5135314668096368, 'colsample_bytree': 0.5506352830088178, 'weight_rf': 0.40048661643075334, 'weight_xgb': 0.8966769584665023}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:54:49,733] Trial 23 finished with value: 0.8385107849896583 and parameters: {'n_estimators': 182, 'max_depth': 7, 'learning_rate': 0.0727385641601097, 'subsample': 0.5889320932452425, 'colsample_bytree': 0.5034021263999358, 'weight_rf': 0.37742978975985314, 'weight_xgb': 0.903455843754812}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:54:55,406] Trial 24 finished with value: 0.8455037919826653 and parameters: {'n_estimators': 109, 'max_depth': 6, 'learning_rate': 0.037838151377438276, 'subsample': 0.5377740538947051, 'colsample_bytree': 0.5640569412358197, 'weight_rf': 0.5449535999514982, 'weight_xgb': 0.9263938434900807}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:54:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:55:01,532] Trial 25 finished with value: 0.8385206342952822 and parameters: {'n_estimators': 134, 'max_depth': 7, 'learning_rate': 0.05365173647450867, 'subsample': 0.6536753356251905, 'colsample_bytree': 0.6741976152634733, 'weight_rf': 0.18811525406896926, 'weight_xgb': 0.7230085927936858}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:55:07,905] Trial 26 finished with value: 0.8483600906136118 and parameters: {'n_estimators': 201, 'max_depth': 9, 'learning_rate': 0.07968572127660102, 'subsample': 0.6077815254268758, 'colsample_bytree': 0.6113595279801278, 'weight_rf': 0.716206556408449, 'weight_xgb': 0.7670516552368838}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:55:14,441] Trial 27 finished with value: 0.8483206933911159 and parameters: {'n_estimators': 213, 'max_depth': 9, 'learning_rate': 0.015251930340680916, 'subsample': 0.6040187014547574, 'colsample_bytree': 0.606819747326354, 'weight_rf': 0.7047068858162068, 'weight_xgb': 0.7655565880875084}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:55:21,301] Trial 28 finished with value: 0.8384812370727864 and parameters: {'n_estimators': 276, 'max_depth': 9, 'learning_rate': 0.02184940118039523, 'subsample': 0.5325302481144973, 'colsample_bytree': 0.6530410373383945, 'weight_rf': 0.510940973785709, 'weight_xgb': 0.5315581798000358}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:55:27,863] Trial 29 finished with value: 0.8385009356840343 and parameters: {'n_estimators': 185, 'max_depth': 10, 'learning_rate': 0.03515663206499067, 'subsample': 0.6680927995202108, 'colsample_bytree': 0.7140034518141628, 'weight_rf': 0.7904585288274637, 'weight_xgb': 0.8490815214629208}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:55:34,542] Trial 30 finished with value: 0.8441150398896877 and parameters: {'n_estimators': 239, 'max_depth': 4, 'learning_rate': 0.0427934067606342, 'subsample': 0.5020348823145372, 'colsample_bytree': 0.5517209858035437, 'weight_rf': 0.34983120563475056, 'weight_xgb': 0.83085403969824}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:55:40,837] Trial 31 finished with value: 0.8455037919826651 and parameters: {'n_estimators': 89, 'max_depth': 8, 'learning_rate': 0.07744131398093675, 'subsample': 0.5806201060021957, 'colsample_bytree': 0.524720029261927, 'weight_rf': 0.8763986838011247, 'weight_xgb': 0.8690845227606468}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:55:46,871] Trial 32 finished with value: 0.8385107849896583 and parameters: {'n_estimators': 151, 'max_depth': 6, 'learning_rate': 0.06521913845775089, 'subsample': 0.5504503000271508, 'colsample_bytree': 0.5834275432311745, 'weight_rf': 0.39715146543125746, 'weight_xgb': 0.9840597037096277}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:55:52,891] Trial 33 finished with value: 0.8455333398995369 and parameters: {'n_estimators': 185, 'max_depth': 5, 'learning_rate': 0.08196326436785278, 'subsample': 0.5993754840744484, 'colsample_bytree': 0.6058463659349473, 'weight_rf': 0.5761230468255194, 'weight_xgb': 0.9033712228603232}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:55:58,725] Trial 34 finished with value: 0.8483108440854921 and parameters: {'n_estimators': 89, 'max_depth': 9, 'learning_rate': 0.029474812034069587, 'subsample': 0.5333508680271629, 'colsample_bytree': 0.5296755360812487, 'weight_rf': 0.696141128849164, 'weight_xgb': 0.754883388619602}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:55:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:56:04,559] Trial 35 finished with value: 0.8385009356840343 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.06120235957413056, 'subsample': 0.6439595663170142, 'colsample_bytree': 0.6292756966512509, 'weight_rf': 0.9132907246032785, 'weight_xgb': 0.6818670717836367}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:56:10,782] Trial 36 finished with value: 0.8427262877967104 and parameters: {'n_estimators': 205, 'max_depth': 7, 'learning_rate': 0.024677650040257453, 'subsample': 0.6974226783025035, 'colsample_bytree': 0.7755537884598794, 'weight_rf': 0.30964332272842776, 'weight_xgb': 0.8065227780880991}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:56:16,578] Trial 37 finished with value: 0.8497291440953413 and parameters: {'n_estimators': 91, 'max_depth': 10, 'learning_rate': 0.05336322522570902, 'subsample': 0.5781471546826278, 'colsample_bytree': 0.5803327907118289, 'weight_rf': 0.4751529937745752, 'weight_xgb': 0.8846789018565054}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:56:23,278] Trial 38 finished with value: 0.8357037328868315 and parameters: {'n_estimators': 244, 'max_depth': 10, 'learning_rate': 0.054910696478912106, 'subsample': 0.5210087205131617, 'colsample_bytree': 0.6658329993347902, 'weight_rf': 0.4621810255616387, 'weight_xgb': 0.4671864766230994}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:56:29,238] Trial 39 finished with value: 0.8454939426770413 and parameters: {'n_estimators': 84, 'max_depth': 10, 'learning_rate': 0.06052448465216441, 'subsample': 0.6255300420623129, 'colsample_bytree': 0.5849764425317525, 'weight_rf': 0.415463161092907, 'weight_xgb': 0.3753632428162963}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:56:35,206] Trial 40 finished with value: 0.8399192356938835 and parameters: {'n_estimators': 137, 'max_depth': 9, 'learning_rate': 0.08658643458580936, 'subsample': 0.7494040952471688, 'colsample_bytree': 0.7330701463420616, 'weight_rf': 0.49461646034727086, 'weight_xgb': 0.9445639956572648}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:56:40,991] Trial 41 finished with value: 0.8539446469023932 and parameters: {'n_estimators': 85, 'max_depth': 8, 'learning_rate': 0.07390891979399793, 'subsample': 0.5729604528636011, 'colsample_bytree': 0.5394911994765266, 'weight_rf': 0.5836635889378566, 'weight_xgb': 0.8820044842433504}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:56:46,617] Trial 42 finished with value: 0.8497192947897174 and parameters: {'n_estimators': 83, 'max_depth': 8, 'learning_rate': 0.06715349715556082, 'subsample': 0.5959593759023342, 'colsample_bytree': 0.5424051074878934, 'weight_rf': 0.5796435447898555, 'weight_xgb': 0.8018512970176104}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:56:52,473] Trial 43 finished with value: 0.8483206933911159 and parameters: {'n_estimators': 73, 'max_depth': 8, 'learning_rate': 0.05005161617417804, 'subsample': 0.5502918153638722, 'colsample_bytree': 0.5448077077435659, 'weight_rf': 0.5690958901600548, 'weight_xgb': 0.8083416729534805}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:56:58,903] Trial 44 finished with value: 0.8427164384910864 and parameters: {'n_estimators': 94, 'max_depth': 8, 'learning_rate': 0.0675118349703106, 'subsample': 0.8950326862022744, 'colsample_bytree': 0.538146764831977, 'weight_rf': 0.6159331926765264, 'weight_xgb': 0.8704978976689747}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:56:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:57:04,522] Trial 45 finished with value: 0.8441051905840637 and parameters: {'n_estimators': 58, 'max_depth': 6, 'learning_rate': 0.04017658474838718, 'subsample': 0.5852378214768333, 'colsample_bytree': 0.5773029345040573, 'weight_rf': 0.48270823156788134, 'weight_xgb': 0.951601832303856}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:57:11,522] Trial 46 finished with value: 0.848300994779868 and parameters: {'n_estimators': 469, 'max_depth': 5, 'learning_rate': 0.0100644458221411, 'subsample': 0.5250101225118576, 'colsample_bytree': 0.6289042813527399, 'weight_rf': 0.6571969215468003, 'weight_xgb': 0.7193260539710717}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:57:17,256] Trial 47 finished with value: 0.8483403920023639 and parameters: {'n_estimators': 125, 'max_depth': 8, 'learning_rate': 0.06119999120559681, 'subsample': 0.7000177519582769, 'colsample_bytree': 0.5612038665032925, 'weight_rf': 0.5322447431722271, 'weight_xgb': 0.5879928224415355}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:57:22,926] Trial 48 finished with value: 0.8469319412981384 and parameters: {'n_estimators': 73, 'max_depth': 6, 'learning_rate': 0.08958665766989866, 'subsample': 0.7882383103262545, 'colsample_bytree': 0.598953762707035, 'weight_rf': 0.432762520840949, 'weight_xgb': 0.2828110995809408}. Best is trial 22 with value: 0.8567320003939722.\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-12-29 16:57:28,745] Trial 49 finished with value: 0.84833054269674 and parameters: {'n_estimators': 52, 'max_depth': 8, 'learning_rate': 0.05156130499425105, 'subsample': 0.723089376255695, 'colsample_bytree': 0.8639098265626464, 'weight_rf': 0.29556251609397854, 'weight_xgb': 0.8806879872015526}. Best is trial 22 with value: 0.8567320003939722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      " CV : 85.67%\n",
      "   : 86.03%\n",
      "best_params = {\n",
      "    'n_estimators': 97,\n",
      "    'max_depth': 6,\n",
      "    'learning_rate': 0.07602690602356578,\n",
      "    'subsample': 0.5135314668096368,\n",
      "    'colsample_bytree': 0.5506352830088178,\n",
      "    'weight_rf': 0.40048661643075334,\n",
      "    'weight_xgb': 0.8966769584665023,\n",
      "    'random_state': 42\n",
      "}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\system\\python\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"weight_rf\", \"weight_xgb\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "#from sklearn.calibration import CalibratedClassifierCV\n",
    "path = r'C:\\Users\\user\\Documents\\GitHub\\Notebooks-on-ml\\TITANIC\\Data\\train.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "train_df_raw, val_df_raw = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "def get_safe_survival_mapping(train_fs, test_fs):\n",
    "    train_fs = train_fs.copy()\n",
    "    test_fs = test_fs.copy()\n",
    "\n",
    "    train_fs['Surname'] = train_fs['Name'].apply(lambda x: x.split(',')[0].strip())\n",
    "    test_fs['Surname'] = test_fs['Name'].apply(lambda x: x.split(',')[0].strip())\n",
    "\n",
    "    train_fs['Family_Survival'] = 0.5\n",
    "    test_fs['Family_Survival'] = 0.5\n",
    "\n",
    "    for _, group in train_fs.groupby(['Surname', 'Fare']):\n",
    "        if len(group) > 1:\n",
    "            for ind, row in group.iterrows():\n",
    "                others = group.drop(ind)\n",
    "                if others['Survived'].max() == 1.0:\n",
    "                    train_fs.loc[ind, 'Family_Survival'] = 1\n",
    "                elif others['Survived'].max() == 0.0:\n",
    "                    train_fs.loc[ind, 'Family_Survival'] = 0\n",
    "\n",
    "    for _, group in train_fs.groupby('Ticket'):\n",
    "        if len(group) > 1:\n",
    "            for ind, row in group.iterrows():\n",
    "                if train_fs.loc[ind, 'Family_Survival'] == 0.5:\n",
    "                    others = group.drop(ind)\n",
    "                    if others['Survived'].max() == 1.0:\n",
    "                        train_fs.loc[ind, 'Family_Survival'] = 1\n",
    "                    elif others['Survived'].max() == 0.0:\n",
    "                        train_fs.loc[ind, 'Family_Survival'] = 0\n",
    "\n",
    "    for ind, row in test_fs.iterrows():\n",
    "        fam_in_train = train_fs[(train_fs['Surname'] == row['Surname']) & (train_fs['Fare'] == row['Fare'])]\n",
    "        ticket_in_train = train_fs[train_fs['Ticket'] == row['Ticket']]\n",
    "\n",
    "        combined = pd.concat([fam_in_train, ticket_in_train])\n",
    "\n",
    "        if len(combined) > 0:\n",
    "            if combined['Survived'].max() == 1.0:\n",
    "                test_fs.loc[ind, 'Family_Survival'] = 1\n",
    "            elif combined['Survived'].max() == 0.0:\n",
    "                test_fs.loc[ind, 'Family_Survival'] = 0\n",
    "\n",
    "    full_mapping = pd.concat([train_fs[['PassengerId', 'Family_Survival']],\n",
    "                                    test_fs[['PassengerId', 'Family_Survival']]])\n",
    "    return full_mapping\n",
    "\n",
    "def prepare_data(df_input, survival_mapping):\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    df['Ticket_Group_Size'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "    df = df.merge(survival_mapping, on='PassengerId', how='left')\n",
    "    df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "    df['Title'] = df['Title'].replace(['Rev', 'Dr'], 'Service')\n",
    "    df['Title'] = df['Title'].replace(['Jonkheer', 'Don', 'Sir', 'Lady', 'Countess', 'Dona'], 'Noble')\n",
    "    df['Title'] = df['Title'].replace(['Capt', 'Col', 'Major'], 'Officer')\n",
    "    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(float)\n",
    "    df['Has_Cabin'] = df['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "    df['Deck'] = df['Cabin'].str[0].fillna('M')\n",
    "    df['Deck'] = df['Deck'].replace(['A', 'B', 'C'], 'Top')\n",
    "    df['Deck'] = df['Deck'].replace(['D', 'E'], 'Middle')\n",
    "    df['Deck'] = df['Deck'].replace(['F', 'G', 'T', 'M'], 'Low')\n",
    "    df['Age'] = df.groupby('Title')['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    cols_to_drop = ['Name', 'Ticket', 'Cabin', 'PassengerId', 'SibSp', 'Parch']\n",
    "    df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['Title', 'Deck', 'Embarked'])\n",
    "    \n",
    "    return df.astype(float)\n",
    "\n",
    "fs_map = get_safe_survival_mapping(train_df_raw, val_df_raw)\n",
    "\n",
    "X_train = prepare_data(train_df_raw, fs_map).drop(columns=['Survived'])\n",
    "y_train = train_df_raw['Survived']\n",
    "\n",
    "X_val = prepare_data(val_df_raw, fs_map).drop(columns=['Survived'])\n",
    "y_val = val_df_raw['Survived']\n",
    "\n",
    "X_val = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "def objective(trial):\n",
    "    xgb_params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'random_state': 42,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    w1 = trial.suggest_float('weight_rf', 0.1, 1.0)\n",
    "    w2 = trial.suggest_float('weight_xgb', 0.1, 1.0)\n",
    "    \n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=370, max_depth=6, min_samples_split=12, \n",
    "        min_samples_leaf=4, random_state=42\n",
    "    )\n",
    "    \n",
    "    xgb_model = XGBClassifier(**xgb_params)\n",
    "    \n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[('rf', rf_model), ('xgb', xgb_model)],\n",
    "        voting='soft',\n",
    "        weights=[w1, w2]\n",
    "    )\n",
    "    \n",
    "    score = cross_val_score(ensemble, X_train, y_train, cv=5).mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "xgb_best_params = study.best_params.copy()\n",
    "w_rf = xgb_best_params.pop('weight_rf')\n",
    "w_xgb = xgb_best_params.pop('weight_xgb')\n",
    "best_xgb = XGBClassifier(**study.best_params, random_state=42)\n",
    "best_rf = RandomForestClassifier(n_estimators=370, max_depth=6, min_samples_split=12, min_samples_leaf=4, random_state=42)\n",
    "\n",
    "#calibrated_xgb = CalibratedClassifierCV(best_xgb, method='sigmoid', cv=5)\n",
    "#calibrated_rf = CalibratedClassifierCV(best_rf, method='sigmoid', cv=5)\n",
    "\n",
    "final_model = VotingClassifier(\n",
    "    estimators=[('rf', best_rf), ('xgb', best_xgb)],\n",
    "    voting='soft',\n",
    "    weights=[w_rf, w_xgb]\n",
    ")\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"-\" * 30)\n",
    "print(f\" CV : {study.best_value:.2%}\")\n",
    "print(f\"   : {final_model.score(X_val, y_val):.2%}\")\n",
    "print(\"best_params = {\")\n",
    "for key, value in study.best_params.items():\n",
    "    if isinstance(value, str):\n",
    "        print(f\"    '{key}': '{value}',\")\n",
    "    else:\n",
    "        print(f\"    '{key}': {value},\")\n",
    "print(\"    'random_state': 42\")\n",
    "print(\"}\") \n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title_Noble           0.000000\n",
      "Title_the Countess    0.000000\n",
      "Title_Officer         0.000227\n",
      "Embarked_Q            0.002538\n",
      "Title_Service         0.004340\n",
      "Title_Master          0.007883\n",
      "Deck_Top              0.007930\n",
      "IsAlone               0.008152\n",
      "Embarked_C            0.008245\n",
      "Embarked_S            0.009369\n",
      "Deck_Middle           0.011370\n",
      "Deck_Low              0.028795\n",
      "Has_Cabin             0.032870\n",
      "Ticket_Group_Size     0.038311\n",
      "FamilySize            0.038382\n",
      "Age                   0.050517\n",
      "Title_Miss            0.058907\n",
      "Pclass                0.064554\n",
      "Fare                  0.069725\n",
      "Title_Mrs             0.073751\n",
      "Family_Survival       0.087291\n",
      "Title_Mr              0.192837\n",
      "Sex                   0.204007\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'Actual')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "importances = pd.Series(best_rf.feature_importances_, index=X_train.columns)\n",
    "print(importances.sort_values(ascending=True).head(40))\n",
    "importances.nlargest(10).plot(kind='barh')\n",
    "plt.title('-10     Random Forest')\n",
    "plt.show()\n",
    "\n",
    "errors_df = val_df_raw.copy()\n",
    "errors_df['Actual'] = val_df_raw['Survived']\n",
    "errors_df['Predicted'] = final_model.predict(X_val)\n",
    "errors = errors_df[errors_df['Actual'] != errors_df['Predicted']]\n",
    "errors.head(10)\n",
    "\n",
    "y_probs = final_model.predict_proba(X_val)[:, 1]\n",
    "y_pred_custom = (y_probs >= 0.5).astype(int)\n",
    "sns.heatmap(confusion_matrix(y_val, y_pred_custom), annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
