{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2032f23",
   "metadata": {},
   "source": [
    "functions - not oneliners\n",
    "math - not just functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f935f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "data = pd.read_csv('''C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\notebooks-on-ml\\\\Coursera lil proj\\\\DATA\\\\a_steam_data_2021_2025.csv''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954a8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['genres'] = data['genres'].fillna(data.groupby('categories')['genres'].transform(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan))\n",
    "data['genres'] = data['genres'].replace(['nan', 'None', ''], np.nan)\n",
    "data['categories'] = data['categories'].replace(['nan', 'None', ''], np.nan)\n",
    "data = data.dropna(subset=['genres', 'categories'])\n",
    "data['developer'] = data['developer'].fillna('Noname')\n",
    "data['publisher'] = data['publisher'].fillna('Noname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad9a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['release_date'] = pd.to_datetime(data['release_date'], format='mixed', errors='coerce')\n",
    "data['release_date'] = data['release_date'].fillna(pd.to_datetime('Aug 1 ' + data['release_year'].astype(str), format='%b %d %Y', errors='coerce'))       \n",
    "data['genres'] = data['genres'].astype(str).str.split(';')\n",
    "data['categories'] = data['categories'].astype(str).str.split(';')\n",
    "data = data.sort_values(['release_date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a82ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_sequel'] = data['name'].apply(lambda x: 1 if any(word.upper() in ['2', '3', 'II', 'III', 'IV', 'V'] for word in str(x).split()) else 0).astype(int)\n",
    "data['developer&publisher'] = [1 if any(i in p for i in d) else 0 for d, p in zip(data['developer'], data['publisher'])]\n",
    "\n",
    "data['genre_count'] = data['genres'].apply(len)\n",
    "data['categories_count'] = data['categories'].apply(len)\n",
    "\n",
    "data['niche'] = data['genres'].str[0] + '_' + data['categories'].str[0]\n",
    "dev_gen_seen, dev_cat_seen = {}, {}\n",
    "dg_hist, dc_hist = [], []\n",
    "\n",
    "dev_gen_seen, dev_cat_seen = {}, {}\n",
    "pub_gen_seen, pub_cat_seen = {}, {}\n",
    "dg_hist, dc_hist, pg_hist, pc_hist = [], [], [], []\n",
    "for d, p, g, c in zip(data['developer'], data['publisher'], data['genres'], data['categories']):\n",
    "    d_key, p_key = tuple(d) if isinstance(d, list) else d, tuple(p) if isinstance(p, list) else p\n",
    "    dg_hist.append(list(dev_gen_seen.get(d_key, [])))\n",
    "    dc_hist.append(list(dev_cat_seen.get(d_key, [])))\n",
    "    pg_hist.append(list(pub_gen_seen.get(p_key, [])))\n",
    "    pc_hist.append(list(pub_cat_seen.get(p_key, [])))\n",
    "    dev_gen_seen.setdefault(d_key, set()).update(g)\n",
    "    dev_cat_seen.setdefault(d_key, set()).update(c)\n",
    "    pub_gen_seen.setdefault(p_key, set()).update(g)\n",
    "    pub_cat_seen.setdefault(p_key, set()).update(c)\n",
    "\n",
    "data['developer_genres'] = dg_hist\n",
    "data['developer_categories'] = dc_hist\n",
    "data['publisher_genres'] = pg_hist\n",
    "data['publisher_categories'] = pc_hist\n",
    "data['unique_genres'] = [len(x) for x in dg_hist]\n",
    "data['unique_categories'] = [len(x) for x in dc_hist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1a165f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_price'] = np.log1p(data['price'])\n",
    "data['log_recommendations'] = np.log1p(data['recommendations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_hit'] = data['recommendations'] > 800\n",
    "#data['is_mega_hit'] = data['recommendations'] > 1800\n",
    "data['is_discount'] = (data['price'] % 1) > 0.90\n",
    "data['developer_hit_ratio'] = data.groupby('developer')['is_hit'].transform(lambda x: x.shift(1).expanding().mean()).fillna(0)\n",
    "data['publisher_hit_ratio'] = data.groupby('publisher')['is_hit'].transform(lambda x: x.shift(1).expanding().mean()).fillna(0)\n",
    "data['developer_game_number'] = data.groupby('developer').cumcount() + 1\n",
    "data['publisher_game_number'] = data.groupby('publisher').cumcount() + 1\n",
    "#data['timeliness'] = data['recommendations'] / ((2026 - data['release_date'].astype(str).str.split('-').str[0].astype(int)) * 12 - (data['release_date'].astype(str).str.split('-').str[1].astype(int) - 1)).replace(0, 1)\n",
    "data['release_month'] = data['release_date'].dt.month\n",
    "data['month_sin'] = np.sin(2 * np.pi * data['release_month'] / 12)\n",
    "data['month_cos'] = np.cos(2 * np.pi * data['release_month'] / 12)\n",
    "data['is_new_niche'] = ~data.duplicated(['developer', 'niche'])\n",
    "data['total_niches_count'] = data.groupby('developer')['is_new_niche'].transform(lambda x: x.shift(1).cumsum()).fillna(0)\n",
    "data['is_specialist'] = (data['total_niches_count'] <= 2).astype(int)\n",
    "data['is_veteran'] = (data['niche_count'] >= 3).astype(int)\n",
    "\n",
    "data['developer_genre_overlap'] = [len(set(g) & set(h)) / len(set(g)) if len(g) > 0 else 0 for g, h in zip(data['genres'], data['developer_genres'])]\n",
    "data['developer_category_overlap'] = [len(set(c) & set(h)) / len(set(c)) if len(c) > 0 else 0 for c, h in zip(data['categories'], data['developer_categories'])]\n",
    "data['publisher_genre_overlap'] = [len(set(g) & set(h)) / len(set(g)) if len(g) > 0 else 0 for g, h in zip(data['genres'], data['publisher_genres'])]\n",
    "data['publisher_category_overlap'] = [len(set(c) & set(h)) / len(set(c)) if len(c) > 0 else 0 for c, h in zip(data['categories'], data['publisher_categories'])]\n",
    "data['publisher_niche_count'] = data.groupby(['publisher', 'niche']).cumcount()\n",
    "data['publisher_niche_count'] = data.groupby(['publisher', 'niche'])['publisher_niche_count'].shift(1).fillna(0)\n",
    "data['developer_niche_count'] = data.groupby(['developer', 'niche']).cumcount()\n",
    "data['developer_niche_count'] = data.groupby(['developer', 'niche'])['developer_niche_count'].shift(1).fillna(0)\n",
    "data['developer_std'] = data.groupby('developer')['price'].transform(lambda x: x.shift(1).expanding().std()).fillna(0)\n",
    "data['publisher_std'] = data.groupby('publisher')['price'].transform(lambda x: x.shift(1).expanding().std()).fillna(0)\n",
    "data['price_per_genre'] = data['log_price'] / (data['genre_count'] + 1)\n",
    "\n",
    "data['developer_price'] = data.groupby('developer')['price'].transform(lambda x: x.shift(1).expanding().mean()).fillna(0)\n",
    "data['publisher_price'] = data.groupby('publisher')['price'].transform(lambda x: x.shift(1).expanding().mean()).fillna(0)\n",
    "data['developer_recommendations'] = data.groupby('developer')['recommendations'].transform(lambda x: x.shift(1).expanding().mean()).fillna(0)\n",
    "data['publisher_recommendations'] = data.groupby('publisher')['recommendations'].transform(lambda x: x.shift(1).expanding().mean()).fillna(0)\n",
    "#data['quality'] = data['recommendations'] / (data['price'] + 0.001)\n",
    "#data['developer_quality_ratio'] = data.groupby('developer')['quality'].transform(lambda x: x.shift(1).expanding().mean())\n",
    "#data['publisher_quality_ratio'] = data.groupby('publisher')['quality'].transform(lambda x: x.shift(1).expanding().mean())\n",
    "data['developer_momentum'] = data.groupby('developer')['recommendations'].transform(lambda x: x.diff().shift(1)).fillna(0)\n",
    "#data['developer_niche_recommendations'] = data.groupby(['developer', 'niche'])['recommendations'].transform(lambda x: x.shift(1).expanding().mean())\n",
    "data['publisher_momentum'] = data.groupby('publisher')['recommendations'].transform(lambda x: x.diff().shift(1)).fillna(0)\n",
    "#data['publisher_niche_recommendations'] = data.groupby(['publisher', 'niche'])['recommendations'].transform(lambda x: x.shift(1).expanding().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98bf43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_developer_price'] = np.log1p(data['developer_price'])\n",
    "#data['log_publisher_price'] = np.log1p(data['publisher_price'])\n",
    "data['log_developer_recommendations'] = np.log1p(data['developer_recommendations'])\n",
    "data['log_publisher_recommendations'] = np.log1p(data['publisher_recommendations'])\n",
    "#data['log_quality'] = np.log1p(data['quality'])\n",
    "#data['log_developer_quality_ratio'] = np.log1p(data['developer_quality_ratio'])\n",
    "#data['log_publisher_quality_ratio'] = np.log1p(data['publisher_quality_ratio'])\n",
    "data['log_developer_momentum'] = np.sign(data['developer_momentum']) * np.log1p(np.abs(data['developer_momentum']))\n",
    "#data['log_developer_niche_recommendations'] = np.log1p(data['developer_niche_recommendations'])\n",
    "data['log_publisher_momentum'] = np.sign(data['publisher_momentum']) * np.log1p(np.abs(data['publisher_momentum']))\n",
    "#data['log_publisher_niche_recommendations'] = np.log1p(data['publisher_niche_recommendations'])\n",
    "\n",
    "data['developer_count'] = data['developer'].map(data['developer'].value_counts())\n",
    "data['log_developer_count'] = np.log1p(data['developer_count'])\n",
    "data['publisher_count'] = data['publisher'].map(data['publisher'].value_counts())\n",
    "data['log_publisher_count'] = np.log1p(data['publisher_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "549ce361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inf_counts = np.isinf(data.select_dtypes(include=[np.number])).sum()\n",
    "#print(inf_counts[inf_counts > 0])\n",
    "#print('----------------')\n",
    "#nan_counts = data.isnull().sum()\n",
    "#print(nan_counts[nan_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d3e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_cols = [\n",
    "    'log_price', 'log_developer_price',\n",
    "    'log_developer_recommendations', 'log_publisher_recommendations', \n",
    "#    'log_quality', 'log_developer_quality_ratio', 'log_publisher_quality_ratio', \n",
    "#    'log_publisher_price', 'log_recommendations',\n",
    "    'log_developer_momentum', 'log_publisher_momentum',\n",
    "#    'log_developer_niche_recommendations', 'log_publisher_niche_recommendations',\n",
    "    'developer_niche_count', 'publisher_niche_count',\n",
    "    'log_developer_count', 'log_publisher_count'\n",
    "]\n",
    "minmax_cols = [\n",
    "#    'timeliness', \n",
    "    'genre_count', 'categories_count', \n",
    "    'developer_std', 'publisher_std', \n",
    "    'unique_genres', 'unique_categories',\n",
    "    'developer_genre_overlap', 'developer_category_overlap',\n",
    "    'publisher_genre_overlap', 'publisher_category_overlap'\n",
    "]\n",
    "robust = RobustScaler()\n",
    "data[robust_cols] = robust.fit_transform(data[robust_cols])\n",
    "mms = MinMaxScaler()\n",
    "data[minmax_cols] = mms.fit_transform(data[minmax_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04c3c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "genre_encoded = mlb.fit_transform(data['genres'])\n",
    "genre_df = pd.DataFrame(genre_encoded, columns=mlb.classes_, index=data.index)\n",
    "category_encoded = mlb.fit_transform(data['categories'])\n",
    "category_df = pd.DataFrame(category_encoded, columns=mlb.classes_, index=data.index)\n",
    "data = pd.concat([data, genre_df, category_df], axis=1)\n",
    "data['mobile'] = ((data['Remote Play on Phone'] == 1) | (data['Remote Play on Tablet'] == 1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdce109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\n",
    "    'publisher', 'developer', 'publisher_count', 'developer_count', 'Remote Play on Tablet', \n",
    "    'price', 'recommendations', 'genres', 'categories', 'name', 'niche', 'Remote Play on Phone',\n",
    "    'publisher_genres', 'publisher_categories', 'developer_genres',  'appid',\n",
    "    'developer_momentum', 'publisher_momentum', 'developer_categories', 'release_date',\n",
    "    'publisher_price', 'developer_price', 'developer_recommendations', 'log_developer_recommendations',\n",
    "    'publisher_recommendations', 'log_publisher_recommendations', 'release_month',\n",
    "    'Family Sharing', 'PvP', 'Co-op', 'Shared/Split Screen', 'log_recommendations'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('transition_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('transition_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b69031c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('is_hit', axis=1)\n",
    "y = data['is_hit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48090b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundant columns to drop: ['developer_niche_count']\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = data.select_dtypes(include=[np.number]).corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "print(f\"Redundant columns to drop: {to_drop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adc75e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most redundant pairs:\n",
      "developer_niche_count  niche_count                   1.000000\n",
      "developer_game_number  niche_count                   0.875792\n",
      "developer_niche_count  developer_game_number         0.875792\n",
      "publisher_niche_count  publisher_game_number         0.853333\n",
      "price_per_genre        log_price                     0.833792\n",
      "log_publisher_count    log_developer_count           0.774113\n",
      "VR Only                Tracked Controller Support    0.751727\n",
      "unique_categories      categories_count              0.751136\n",
      "log_developer_count    total_niches_count            0.748377\n",
      "publisher_niche_count  niche_count                   0.732975\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pairs = upper.unstack().dropna()\n",
    "sorted_pairs = pairs.sort_values(ascending=False)\n",
    "print(\"Top 10 most redundant pairs:\")\n",
    "print(sorted_pairs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf4dc4",
   "metadata": {},
   "source": [
    "sns.scatterplot(x=data['publisher_std'], y=data['developer_std'])\n",
    "plt.title(\"Visualizing Redundancy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6e47c",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "subset = data.iloc[:, :30] \n",
    "sns.heatmap(subset.corr(), annot=False, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a93d6c7",
   "metadata": {},
   "source": [
    "plot_data = data.explode('genres').explode('categories')\n",
    "sns.barplot(data=plot_data, x='release_year', y='price')\n",
    "plt.show()\n",
    "sns.barplot(data=plot_data, x='release_year', y='recommendations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d8e26",
   "metadata": {},
   "source": [
    "timeline_data = plot_data.groupby(['release_year', 'genres']).size().reset_index(name='count')\n",
    "timeline_data_2 = plot_data.groupby(['release_year', 'categories']).size().reset_index(name='count')\n",
    "sns.lineplot(data=timeline_data, x='release_year', y='count', hue='genres')\n",
    "plt.show()\n",
    "sns.lineplot(data=timeline_data_2, x='release_year', y='count', hue='categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc46c317",
   "metadata": {},
   "source": [
    "sns.barplot(data=plot_data, x='price', y='genres')\n",
    "plt.show()\n",
    "sns.barplot(data=plot_data, x='price', y='categories')\n",
    "plt.show()\n",
    "sns.barplot(data=plot_data, x='recommendations', y='genres')\n",
    "plt.show()\n",
    "sns.barplot(data=plot_data, x='recommendations', y='categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36a51d",
   "metadata": {},
   "source": [
    "sns.histplot(data['price'], kde=True)\n",
    "plt.show()\n",
    "sns.histplot(data['recommendations'], kde=True)\n",
    "plt.show()\n",
    "sns.histplot(data['log_price'], kde=True)\n",
    "plt.show()\n",
    "sns.histplot(data['log_recommendations'], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import optuna\n",
    "\n",
    "base_models = [\n",
    "    ('xgb', XGBClassifier(n_estimators=400, learning_rate=0.05, max_depth=5)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, min_sample_leaf=5))\n",
    "]\n",
    "up_model = LogisticRegression(c=0.1, max_iter=1000)\n",
    "stack = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    deciders=up_model,\n",
    "    cv=5,\n",
    "    stack_method='predict_proba',\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "multi_model = MultiOutputClassifier(stack)\n",
    "y = data[['is_hit', 'is_sequel']]\n",
    "multi_model.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
