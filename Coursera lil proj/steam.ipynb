{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2032f23",
   "metadata": {},
   "source": [
    "functions - not oneliners\n",
    "math - not just functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "97f935f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "data = pd.read_csv('''C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\notebooks-on-ml\\\\Coursera lil proj\\\\DATA\\\\a_steam_data_2021_2025.csv''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "954a8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['genres'] = data['genres'].fillna(data.groupby('categories')['genres'].transform(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan))\n",
    "data['genres'] = data['genres'].replace(['nan', 'None', ''], np.nan)\n",
    "data['categories'] = data['categories'].replace(['nan', 'None', ''], np.nan)\n",
    "data = data.dropna(subset=['genres', 'categories'])\n",
    "data['developer'] = data['developer'].fillna('Noname')\n",
    "data['publisher'] = data['publisher'].fillna('Noname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4ad9a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['release_date'] = pd.to_datetime(data['release_date'], format='mixed', errors='coerce')\n",
    "data['release_date'] = data['release_date'].fillna(pd.to_datetime('Aug 1 ' + data['release_year'].astype(str), format='%b %d %Y', errors='coerce'))       \n",
    "data['genres'] = data['genres'].astype(str).str.split(';')\n",
    "data['categories'] = data['categories'].astype(str).str.split(';')\n",
    "data = data.sort_values(['release_date', 'developer']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4a82ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_sequel'] = data['name'].apply(lambda x: 1 if any(word.upper() in ['2', '3', 'II', 'III', 'IV', 'V'] for word in str(x).split()) else 0).astype(int)\n",
    "data['developer&publisher'] = [1 if any(i in p for i in d) else 0 for d, p in zip(data['developer'], data['publisher'])]\n",
    "\n",
    "data['genre_count'] = data['genres'].apply(len)\n",
    "data['categories_count'] = data['categories'].apply(len)\n",
    "\n",
    "data['niche'] = data['genres'].str[0] + '_' + data['categories'].str[0]\n",
    "dev_gen_seen, dev_cat_seen = {}, {}\n",
    "dg_hist, dc_hist = [], []\n",
    "\n",
    "dev_gen_seen, dev_cat_seen = {}, {}\n",
    "pub_gen_seen, pub_cat_seen = {}, {}\n",
    "dg_hist, dc_hist, pg_hist, pc_hist = [], [], [], []\n",
    "\n",
    "for d, p, g, c in zip(data['developer'], data['publisher'], data['genres'], data['categories']):\n",
    "    d_key = tuple(d) if isinstance(d, list) else d\n",
    "    p_key = tuple(p) if isinstance(p, list) else p\n",
    "    \n",
    "    dg_hist.append(list(dev_gen_seen.get(d_key, [])))\n",
    "    dc_hist.append(list(dev_cat_seen.get(d_key, [])))\n",
    "    pg_hist.append(list(pub_gen_seen.get(p_key, [])))\n",
    "    pc_hist.append(list(pub_cat_seen.get(p_key, [])))\n",
    "    \n",
    "    dev_gen_seen.setdefault(d_key, set()).update(g)\n",
    "    dev_cat_seen.setdefault(d_key, set()).update(c)\n",
    "    pub_gen_seen.setdefault(p_key, set()).update(g)\n",
    "    pub_cat_seen.setdefault(p_key, set()).update(c)\n",
    "\n",
    "data['developer_genres'] = dg_hist\n",
    "data['developer_categories'] = dc_hist\n",
    "data['publisher_genres'] = pg_hist\n",
    "data['publisher_categories'] = pc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e1a165f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_price'] = np.log1p(data['price'])\n",
    "data['log_recommendations'] = np.log1p(data['recommendations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8032e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_hit'] = (data['recommendations'] > 800).astype(int)\n",
    "#data['is_mega_hit'] = data['recommendations'] > 1800\n",
    "data['is_discount'] = (data['price'] % 1 > 0.90).astype(int)\n",
    "data['release_month'] = data['release_date'].dt.month\n",
    "data['month_sin'] = np.sin(2 * np.pi * data['release_month'] / 12)\n",
    "data['month_cos'] = np.cos(2 * np.pi * data['release_month'] / 12)\n",
    "data['genre_count'] = data['genres'].apply(len)\n",
    "data['categories_count'] = data['categories'].apply(len)\n",
    "data['niche'] = data['genres'].str[0] + '_' + data['categories'].str[0]\n",
    "#data['price_per_genre'] = data['log_price'] / (data['genre_count'] + 1)\n",
    "\n",
    "dev_stats = {}\n",
    "pub_stats = {}\n",
    "\n",
    "res = {k: [] for k in [\n",
    "    'dev_hit_ratio', 'pub_hit_ratio', 'dev_avg_price', 'pub_avg_price',\n",
    "    'dev_std_price', 'pub_std_price', 'dev_avg_recs', 'pub_avg_recs',\n",
    "    'dev_mom', 'pub_mom', 'dev_gen_h', 'dev_cat_h', 'pub_gen_h', 'pub_cat_h'\n",
    "]}\n",
    "\n",
    "for d, p, h, pr, rec, g, c in zip(data['developer'], data['publisher'], data['is_hit'], \n",
    "                                  data['price'], data['recommendations'], data['genres'], data['categories']):\n",
    "    \n",
    "    for ent, stats, pref in [(d, dev_stats, 'dev'), (p, pub_stats, 'pub')]:\n",
    "        if ent not in stats:\n",
    "            stats[ent] = [0, 0, 0.0, 0.0, 0.0, 0.0, set(), set()]\n",
    "        \n",
    "        s = stats[ent]\n",
    "        n = s[1]\n",
    "\n",
    "        res[f'{pref}_hit_ratio'].append(s[0]/n if n>0 else 0)\n",
    "        res[f'{pref}_avg_price'].append(s[2]/n if n>0 else 0)\n",
    "        res[f'{pref}_avg_recs'].append(s[4]/n if n>0 else 0)\n",
    "        res[f'{pref}_mom'].append(rec - s[5] if n>0 else 0)\n",
    "        res[f'{pref}_gen_h'].append(list(s[6]))\n",
    "        res[f'{pref}_cat_h'].append(list(s[7]))\n",
    "        \n",
    "        if n > 1:\n",
    "            var = (s[3] / n) - (s[2] / n)**2\n",
    "            res[f'{pref}_std_price'].append(np.sqrt(max(0, var)))\n",
    "        else:\n",
    "            res[f'{pref}_std_price'].append(0)\n",
    "\n",
    "        s[0] += h\n",
    "        s[1] += 1\n",
    "        s[2] += pr\n",
    "        s[3] += pr**2\n",
    "        s[4] += rec\n",
    "        s[5] = rec\n",
    "        s[6].update(g)\n",
    "        s[7].update(c)\n",
    "\n",
    "data['developer_hit_ratio'] = res['dev_hit_ratio']\n",
    "data['publisher_hit_ratio'] = res['pub_hit_ratio']\n",
    "data['developer_price'] = res['dev_avg_price']\n",
    "data['publisher_price'] = res['pub_avg_price']\n",
    "data['developer_std'] = res['dev_std_price']\n",
    "data['publisher_std'] = res['pub_std_price']\n",
    "data['developer_recommendations'] = res['dev_avg_recs']\n",
    "data['publisher_recommendations'] = res['pub_avg_recs']\n",
    "data['developer_momentum'] = res['dev_mom']\n",
    "data['publisher_momentum'] = res['pub_mom']\n",
    "\n",
    "#data['unique_genres'] = [len(x) for x in res['dev_gen_h']]\n",
    "#data['unique_categories'] = [len(x) for x in res['dev_cat_h']]\n",
    "\n",
    "#data['developer_genre_overlap'] = [len(set(g) & set(h))/len(g) if len(g)>0 and h else 0 for g, h in zip(data['genres'], res['dev_gen_h'])]\n",
    "#data['developer_category_overlap'] = [len(set(c) & set(h))/len(c) if len(c)>0 and h else 0 for c, h in zip(data['categories'], res['dev_cat_h'])]\n",
    "#data['publisher_genre_overlap'] = [len(set(g) & set(h))/len(g) if len(g)>0 and h else 0 for g, h in zip(data['genres'], res['pub_gen_h'])]\n",
    "#data['publisher_category_overlap'] = [len(set(c) & set(h))/len(c) if len(c)>0 and h else 0 for c, h in zip(data['categories'], res['pub_cat_h'])]\n",
    "\n",
    "data['developer_game_number'] = data.groupby('developer').cumcount()\n",
    "data['developer_game_number'] = data.groupby('developer')['developer_game_number'].shift(1).fillna(0).astype(int)\n",
    "data['publisher_game_number'] = data.groupby('publisher').cumcount()\n",
    "data['publisher_game_number'] = data.groupby('publisher')['publisher_game_number'].shift(1).fillna(0).astype(int)\n",
    "\n",
    "data['publisher_niche_count'] = data.groupby(['publisher', 'niche']).cumcount()\n",
    "data['publisher_niche_count'] = data.groupby(['publisher', 'niche'])['publisher_niche_count'].shift(1).fillna(0).astype(int)\n",
    "data['developer_niche_count'] = data.groupby(['developer', 'niche']).cumcount()\n",
    "data['developer_niche_count'] = data.groupby(['developer', 'niche'])['developer_niche_count'].shift(1).fillna(0).astype(int)\n",
    "\n",
    "data['is_new_niche'] = ~data.duplicated(['developer', 'niche'])\n",
    "data['total_niches_count'] = data.groupby('developer')['is_new_niche'].cumsum()\n",
    "data['total_niches_count'] = data.groupby('developer')['total_niches_count'].shift(1).fillna(0).astype(int)\n",
    "data['is_specialist'] = (data['total_niches_count'] <= 2).astype(int)\n",
    "#data['is_veteran'] = (data['developer_niche_count'] >= 3).astype(int)\n",
    "\n",
    "#data['timeliness'] = data['recommendations'] / ((2026 - data['release_date'].astype(str).str.split('-').str[0].astype(int)) * 12 - (data['release_date'].astype(str).str.split('-').str[1].astype(int) - 1)).replace(0, 1)\n",
    "#data['quality'] = data['recommendations'] / (data['price'] + 0.001)\n",
    "#data['developer_quality_ratio'] = data.groupby('developer')['quality'].transform(lambda x: x.shift(1).expanding().mean())\n",
    "#data['publisher_quality_ratio'] = data.groupby('publisher')['quality'].transform(lambda x: x.shift(1).expanding().mean())\n",
    "#data['developer_niche_recommendations'] = data.groupby(['developer', 'niche'])['recommendations'].transform(lambda x: x.shift(1).expanding().mean())\n",
    "#data['publisher_niche_recommendations'] = data.groupby(['publisher', 'niche'])['recommendations'].transform(lambda x: x.shift(1).expanding().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "98bf43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_developer_price'] = np.log1p(data['developer_price'])\n",
    "#data['log_publisher_price'] = np.log1p(data['publisher_price'])\n",
    "data['log_developer_recommendations'] = np.log1p(data['developer_recommendations'])\n",
    "data['log_publisher_recommendations'] = np.log1p(data['publisher_recommendations'])\n",
    "#data['log_quality'] = np.log1p(data['quality'])\n",
    "#data['log_developer_quality_ratio'] = np.log1p(data['developer_quality_ratio'])\n",
    "#data['log_publisher_quality_ratio'] = np.log1p(data['publisher_quality_ratio'])\n",
    "data['log_developer_momentum'] = np.sign(data['developer_momentum']) * np.log1p(np.abs(data['developer_momentum']))\n",
    "#data['log_developer_niche_recommendations'] = np.log1p(data['developer_niche_recommendations'])\n",
    "data['log_publisher_momentum'] = np.sign(data['publisher_momentum']) * np.log1p(np.abs(data['publisher_momentum']))\n",
    "#data['log_publisher_niche_recommendations'] = np.log1p(data['publisher_niche_recommendations'])\n",
    "data['log_total_niches_count'] = np.log1p(data['total_niches_count'])\n",
    "data['log_developer_game_number'] = np.log1p(data['developer_game_number'])\n",
    "data['log_publisher_game_number'] = np.log1p(data['publisher_game_number'])\n",
    "data['log_developer_std'] = np.log1p(data['developer_std']) \n",
    "data['log_publisher_std'] = np.log1p(data['publisher_std'])\n",
    "\n",
    "data['developer_game_number'] = data.groupby('developer').cumcount() + 1\n",
    "data['publisher_game_number'] = data.groupby('publisher').cumcount() + 1\n",
    "data['log_developer_game_number'] = np.log1p(data['developer_game_number'])\n",
    "data['log_publisher_game_number'] = np.log1p(data['publisher_game_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "549ce361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inf_counts = np.isinf(data.select_dtypes(include=[np.number])).sum()\n",
    "#print(inf_counts[inf_counts > 0])\n",
    "#print('----------------')\n",
    "#nan_counts = data.isnull().sum()\n",
    "#print(nan_counts[nan_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f0d3e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_cols = [\n",
    "    'log_price', 'log_developer_price',\n",
    "    'log_developer_recommendations', 'log_publisher_recommendations', \n",
    "#    'log_quality', 'log_developer_quality_ratio', 'log_publisher_quality_ratio', \n",
    "#    'log_publisher_price', 'log_recommendations',\n",
    "    'log_developer_momentum', 'log_publisher_momentum',\n",
    "#    'log_developer_niche_recommendations', 'log_publisher_niche_recommendations',\n",
    "    'developer_niche_count', 'publisher_niche_count',\n",
    "#    'log_developer_count', 'log_publisher_count',\n",
    "    'log_total_niches_count',\n",
    "    'log_developer_std', 'log_publisher_std',\n",
    "]\n",
    "minmax_cols = [\n",
    "#    'timeliness', \n",
    "    'genre_count', 'categories_count',  \n",
    "#    'unique_genres', 'unique_categories',\n",
    "#    'developer_category_overlap', 'publisher_category_overlap',\n",
    "#    'developer_genre_overlap', 'publisher_genre_overlap',\n",
    "    'month_sin', 'month_cos'\n",
    "]\n",
    "robust = RobustScaler()\n",
    "data[robust_cols] = robust.fit_transform(data[robust_cols])\n",
    "mms = MinMaxScaler()\n",
    "data[minmax_cols] = mms.fit_transform(data[minmax_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "04c3c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "genre_sparse = mlb.fit_transform(data['genres'])\n",
    "genre_df = pd.DataFrame.sparse.from_spmatrix(\n",
    "    genre_sparse, \n",
    "    columns=mlb.classes_, \n",
    "    index=data.index\n",
    ")\n",
    "category_sparse = mlb.fit_transform(data['categories'])\n",
    "category_df = pd.DataFrame.sparse.from_spmatrix(\n",
    "    category_sparse, \n",
    "    columns=mlb.classes_, \n",
    "    index=data.index\n",
    ")\n",
    "mobile_cols = [c for c in category_df.columns if 'Remote Play on Phone' in c or 'Remote Play on Tablet' in c]\n",
    "data['mobile'] = category_df[mobile_cols].any(axis=1).astype('int8')\n",
    "data = pd.concat([data.drop(columns=['genres', 'categories']), genre_df, category_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bdce109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\n",
    "    'publisher', 'developer', 'price', 'name', 'niche', 'appid', 'release_date',\n",
    "    'publisher_genres', 'publisher_categories', 'developer_genres', 'developer_categories',\n",
    "    'publisher_price', 'developer_price', 'developer_recommendations', \n",
    "    'publisher_recommendations', 'total_niches_count', 'developer_game_number', \n",
    "    'publisher_game_number', 'release_year', 'release_month', 'recommendations', \n",
    "    'Remote Play on Phone', 'Remote Play on Tablet', 'Online PvP', 'Family Sharing',\n",
    "    'Online Co-op', 'Shared/Split Screen', 'publisher_std', 'developer_std'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3381e878",
   "metadata": {},
   "source": [
    "data.to_csv('transition_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d69b489",
   "metadata": {},
   "source": [
    "data = pd.read_csv('transition_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69031c8",
   "metadata": {},
   "source": [
    "X = data.drop('is_hit', axis=1)\n",
    "y = data['is_hit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "48090b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundant columns to drop: []\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = data.select_dtypes(include=[np.number]).corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "print(f\"Redundant columns to drop: {to_drop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "adc75e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most redundant pairs:\n",
      "log_developer_game_number      log_total_niches_count        0.831591\n",
      "log_publisher_game_number      log_developer_game_number     0.767126\n",
      "PvP                            Multi-player                  0.760442\n",
      "VR Only                        Tracked Controller Support    0.751727\n",
      "log_total_niches_count         log_developer_price           0.746864\n",
      "Multi-player                   Co-op                         0.738777\n",
      "developer_niche_count          publisher_niche_count         0.732913\n",
      "log_developer_game_number      developer_niche_count         0.721223\n",
      "Playable without Timed Input   Custom Volume Controls        0.721134\n",
      "log_publisher_recommendations  publisher_hit_ratio           0.698531\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pairs = upper.unstack().dropna()\n",
    "sorted_pairs = pairs.sort_values(ascending=False)\n",
    "print(\"Top 10 most redundant pairs:\")\n",
    "print(sorted_pairs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf4dc4",
   "metadata": {},
   "source": [
    "sns.scatterplot(x=data['publisher_std'], y=data['developer_std'])\n",
    "plt.title(\"Visualizing Redundancy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6e47c",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "subset = data.iloc[:, :30] \n",
    "sns.heatmap(subset.corr(), annot=False, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a93d6c7",
   "metadata": {},
   "source": [
    "plot_data = data.explode('genres').explode('categories')\n",
    "sns.barplot(data=plot_data, x='release_year', y='price')\n",
    "plt.show()\n",
    "sns.barplot(data=plot_data, x='release_year', y='recommendations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d8e26",
   "metadata": {},
   "source": [
    "timeline_data = plot_data.groupby(['release_year', 'genres']).size().reset_index(name='count')\n",
    "timeline_data_2 = plot_data.groupby(['release_year', 'categories']).size().reset_index(name='count')\n",
    "sns.lineplot(data=timeline_data, x='release_year', y='count', hue='genres')\n",
    "plt.show()\n",
    "sns.lineplot(data=timeline_data_2, x='release_year', y='count', hue='categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc46c317",
   "metadata": {},
   "source": [
    "sns.barplot(data=plot_data, x='price', y='genres')\n",
    "plt.show()\n",
    "sns.barplot(data=plot_data, x='price', y='categories')\n",
    "plt.show()\n",
    "sns.barplot(data=plot_data, x='recommendations', y='genres')\n",
    "plt.show()\n",
    "sns.barplot(data=plot_data, x='recommendations', y='categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36a51d",
   "metadata": {},
   "source": [
    "sns.histplot(data['price'], kde=True)\n",
    "plt.show()\n",
    "sns.histplot(data['recommendations'], kde=True)\n",
    "plt.show()\n",
    "sns.histplot(data['log_price'], kde=True)\n",
    "plt.show()\n",
    "sns.histplot(data['log_recommendations'], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e64604b",
   "metadata": {},
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import optuna\n",
    "\n",
    "base_models = [\n",
    "    ('xgb', XGBClassifier(n_estimators=400, learning_rate=0.05, max_depth=5)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, min_sample_leaf=5))\n",
    "]\n",
    "up_model = LogisticRegression(c=0.1, max_iter=1000)\n",
    "stack = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=up_model,\n",
    "    cv=5,\n",
    "    stack_method='predict_proba',\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "multi_model = MultiOutputClassifier(stack)\n",
    "y = data[['is_hit', 'is_sequel']]\n",
    "multi_model.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
